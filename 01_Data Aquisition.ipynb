{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aquisition Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Flight Delay Central Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of:\n",
    "- source\n",
    "- aquisition process\n",
    "- number of rows\n",
    "- description of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting delay time information\n",
    "Four our project we relied heavily on the Bureau of Transportation Statistics (BTS) as our main source of data(<http://www.transtats.bts.gov/>). Luckily, the BTS offers detailed delay time data which can be downloaded (<http://www.transtats.bts.gov/Tables.asp?DB_ID=120&DB_Name=Airline%20On-Time%20Performance%20Data&DB_Short_Name=On-Time>). However, it is not possible to download the data over a specified period of time, i.e. one can only download data for a month in a given year. To get the data automatically we developed a scrapter tool in Python, which automatically performs the requests and downloads the data. Files adressing this issue can be found in the `src` folder. Scraping the data for ~25 years needs around 2-3 hours as requests are processed slowly on the server side. Furthermore, the BTS provides LookUp Tables for airline codes which have been downloaded manually.\n",
    "\n",
    "The data for each month is around 250-300MB uncompressed (comma separated), which required to filter it. A first step to do so is restricting the columns. In our analysis we use 30 columns, for which a description is available at <http://www.transtats.bts.gov/TableInfo.asp?Table_ID=236&DB_Short_Name=On-Time&Info_Only=0>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aircraft Information Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of:\n",
    "- source\n",
    "- aquisition process\n",
    "- number of rows\n",
    "- description of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of:\n",
    "- source\n",
    "- aquisition process\n",
    "- number of rows\n",
    "- description of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A natural cause for many delays seems to be the weather. We decided to include weather data additionally in our analysis. Therefore, we wanted to get historical weather information of the airports. Unfortunately, when it comes to weather data, there are no public available sources which we found that provide a suitable dataset. However, Wunderground provides a webinterface allowing to query specific IATA / IAOC codes of airports (see i.e. <http://www.wunderground.com/history/airport/EDDF/2005/10/3/DailyHistory.html?req_city=Frankfurt+%2F+Main&req_state=&req_statename=Germany&reqdb.zip=00000&reqdb.magic=5&reqdb.wmo=10637>). Writing a script allowed us to get historic data of individual airports. \n",
    "\n",
    "<table>\n",
    "<tr><td>events</td><td>a list containing strings of weather events, i.e. \"Rain\", \"Fog\", \"Snow\"</td></tr>\n",
    "<tr><td>humidity</td><td>humidity measured in percent</td></tr>\n",
    "<tr><td>precipitation</td><td>precipitation measured in inches </td></tr>\n",
    "<tr><td>sealevelpressure</td><td>pressure at sea level in inches</td></tr>\n",
    "<tr><td>snowdepth</td><td>snow depth in inches</td></tr>\n",
    "<tr><td>snowfall</td><td>snow fall in inches</td></tr>\n",
    "<tr><td>temperature</td><td>temperature in degree Fahrenheit</td></tr>\n",
    "<tr><td>visibility</td><td>visibility in miles</td></tr>\n",
    "<tr><td>windspeed</td><td>wind speed in miles per hour</td></tr>\n",
    "</table>\n",
    " \n",
    "One drawback of this method is similiar to getting the data from the BTS the slow processing of requests from the server and the amount of requests necessary to get data matching the huge dataset of the BTS. We decided to focus on some airports only thus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
