{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrival delay time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import required modules for prediction tasks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import zipfile\n",
    "import StringIO\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import requests, zipfile, StringIO\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we want to develop a model to predict arrival delay time for flights between two cities. As our primary example we investigate flights from New York(all airports) to Chicago(all airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given a list of column labels remove all columns that are in the df\n",
    "def filterDF(df, cols):\n",
    "    colsToKeep = list(set(df.columns) & set(cols))\n",
    "    \n",
    "    return df[colsToKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given a dataframe this function groups all manufacturers into one category whose market share is low (default: 1%)\n",
    "# also groups together some companies\n",
    "def compressManufacturers(df, percentage=1.):\n",
    "    df['AIRCRAFT_MFR'] = df['AIRCRAFT_MFR'].map(lambda x: x.strip())\n",
    "    mfr_stats = df['AIRCRAFT_MFR'].value_counts()\n",
    "    \n",
    "    market_share = mfr_stats.values * 100. / np.sum(mfr_stats.values)\n",
    "    idxs = np.where(market_share < percentage)\n",
    "    names = np.array([el for el in list(mfr_stats.keys())])\n",
    "\n",
    "    # get labels for small manufacturers\n",
    "    smallMFR = names[idxs]\n",
    "\n",
    "    # perform merging for the big companies\n",
    "    # Douglas airplanes\n",
    "    df.loc[df['AIRCRAFT_MFR'] == 'MCDONNELL DOUGLAS AIRCRAFT CO', 'AIRCRAFT_MFR'] = 'MCDONNELL DOUGLAS'\n",
    "    df.loc[df['AIRCRAFT_MFR'] == 'MCDONNELL DOUGLAS CORPORATION', 'AIRCRAFT_MFR'] = 'MCDONNELL DOUGLAS'\n",
    "    df.loc[df['AIRCRAFT_MFR'] == 'MCDONNELL DOUGLAS CORPORATION', 'AIRCRAFT_MFR'] = 'DOUGLAS'\n",
    "\n",
    "    # Embraer\n",
    "    df.loc[df['AIRCRAFT_MFR'] == 'EMBRAER S A', 'AIRCRAFT_MFR'] = 'EMBRAER'\n",
    "\n",
    "    # Airbus\n",
    "    df.loc[df['AIRCRAFT_MFR'] == 'AIRBUS INDUSTRIE', 'AIRCRAFT_MFR'] = 'AIRBUS'\n",
    "\n",
    "    # the small manufacturers\n",
    "    for name in smallMFR:\n",
    "        df.loc[df['AIRCRAFT_MFR'] == name, 'AIRCRAFT_MFR'] = 'SMALL'\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get external aircraft data load additional data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = zipfile.ZipFile('externalData/AircraftInformation.zip')\n",
    "df_master  = pd.DataFrame.from_csv(z.open('MASTER.txt'))\n",
    "df_aircrafts  = pd.DataFrame.from_csv(z.open('ACFTREF.txt'))\n",
    "master = df_master[['MFR MDL CODE', 'YEAR MFR']].reset_index()\n",
    "aircrafts = df_aircrafts['MFR'].reset_index()\n",
    "master.columns = ['TAIL_NUM', 'CODE', 'YEAR']\n",
    "aircrafts.columns = ['CODE', 'MFR']\n",
    "joinedAircraftInfo = pd.merge(master, aircrafts, how='left', on='CODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joinedAircraftInfo.TAIL_NUM = joinedAircraftInfo.TAIL_NUM.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# possible fields\n",
    "# [u'YEAR', u'QUARTER', u'MONTH', u'DAY_OF_MONTH', u'DAY_OF_WEEK',\n",
    "#        u'FL_DATE', u'UNIQUE_CARRIER', u'AIRLINE_ID', u'CARRIER', u'TAIL_NUM',\n",
    "#        u'FL_NUM', u'ORIGIN', u'ORIGIN_CITY_NAME', u'ORIGIN_STATE_ABR',\n",
    "#        u'ORIGIN_STATE_FIPS', u'ORIGIN_STATE_NM', u'ORIGIN_WAC', u'DEST',\n",
    "#        u'DEST_CITY_NAME', u'DEST_STATE_ABR', u'DEST_STATE_FIPS',\n",
    "#        u'DEST_STATE_NM', u'DEST_WAC', u'CRS_DEP_TIME', u'DEP_TIME',\n",
    "#        u'DEP_DELAY', u'DEP_DELAY_NEW', u'DEP_DEL15', u'DEP_DELAY_GROUP',\n",
    "#        u'DEP_TIME_BLK', u'TAXI_OUT', u'WHEELS_OFF', u'WHEELS_ON', u'TAXI_IN',\n",
    "#        u'CRS_ARR_TIME', u'ARR_TIME', u'ARR_DELAY', u'ARR_DELAY_NEW',\n",
    "#        u'ARR_DEL15', u'ARR_DELAY_GROUP', u'ARR_TIME_BLK', u'CANCELLED',\n",
    "#        u'CANCELLATION_CODE', u'DIVERTED', u'CRS_ELAPSED_TIME',\n",
    "#        u'ACTUAL_ELAPSED_TIME', u'AIR_TIME', u'FLIGHTS', u'DISTANCE',\n",
    "#        u'DISTANCE_GROUP', u'CARRIER_DELAY', u'WEATHER_DELAY', u'NAS_DELAY',\n",
    "#        u'SECURITY_DELAY', u'LATE_AIRCRAFT_DELAY', u'FIRST_DEP_TIME',\n",
    "#        u'TOTAL_ADD_GTIME', u'LONGEST_ADD_GTIME', u'DIV_AIRPORT_LANDINGS',\n",
    "#        u'DIV_REACHED_DEST', u'DIV_ACTUAL_ELAPSED_TIME', u'DIV_ARR_DELAY',\n",
    "#        u'DIV_DISTANCE', u'DIV1_AIRPORT', u'DIV1_WHEELS_ON',\n",
    "#        u'DIV1_TOTAL_GTIME', u'DIV1_LONGEST_GTIME', u'DIV1_WHEELS_OFF',\n",
    "#        u'DIV1_TAIL_NUM', u'DIV2_AIRPORT', u'DIV2_WHEELS_ON',\n",
    "#        u'DIV2_TOTAL_GTIME', u'DIV2_LONGEST_GTIME', u'DIV2_WHEELS_OFF',\n",
    "#        u'DIV2_TAIL_NUM', u'DIV3_AIRPORT', u'DIV3_WHEELS_ON',\n",
    "#        u'DIV3_TOTAL_GTIME', u'DIV3_LONGEST_GTIME', u'DIV3_WHEELS_OFF',\n",
    "#        u'DIV3_TAIL_NUM', u'DIV4_AIRPORT', u'DIV4_WHEELS_ON',\n",
    "#        u'DIV4_TOTAL_GTIME', u'DIV4_LONGEST_GTIME', u'DIV4_WHEELS_OFF',\n",
    "#        u'DIV4_TAIL_NUM', u'DIV5_AIRPORT', u'DIV5_WHEELS_ON',\n",
    "#        u'DIV5_TOTAL_GTIME', u'DIV5_LONGEST_GTIME', u'DIV5_WHEELS_OFF',\n",
    "#        u'DIV5_TAIL_NUM', u'Unnamed: 93', u'AIRCRAFT_YEAR', u'AIRCRAFT_AGE',\n",
    "#        u'AIRCRAFT_MFR']\n",
    "\n",
    "# define here which columns to include in the data extraction process\n",
    "columnsToUse = [u'YEAR', u'QUARTER', u'MONTH', u'DAY_OF_MONTH', u'DAY_OF_WEEK',\n",
    "       u'FL_DATE', u'UNIQUE_CARRIER', u'AIRLINE_ID',u'TAIL_NUM',\n",
    "       u'FL_NUM', u'ORIGIN', u'ORIGIN_CITY_NAME',\n",
    "       u'ORIGIN_STATE_NM', u'ORIGIN_WAC', u'DEST',\n",
    "       u'DEST_CITY_NAME',u'ARR_DELAY', u'ARR_DELAY_NEW',\n",
    "       u'ARR_DEL15', u'CANCELLED', u'DIVERTED', u'DISTANCE',u'AIRCRAFT_YEAR', u'AIRCRAFT_AGE',\n",
    "       u'AIRCRAFT_MFR', u'ARR_TIME', u'DEP_TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given the raw BTS data, this function filters it and returns \n",
    "# a filtered version along with how much percent has been removed\n",
    "def processData(rawData):\n",
    "    # filter for city first\n",
    "    filteredData = rawData[(rawData.ORIGIN_CITY_NAME == city_from) & (rawData.DEST_CITY_NAME == city_to)]\n",
    "\n",
    "    # this is how much percent have been cleaned away!\n",
    "    cleaned_away = filteredData.count()[0]\n",
    "\n",
    "    # remove columns that are not needed for the model\n",
    "    filteredData = filterDF(filteredData, columnsToUse)\n",
    "    filteredData.reset_index(inplace=True)\n",
    "\n",
    "    # perform as next step join to amend information by aircraftdata\n",
    "    delayFinal = filteredData[['TAIL_NUM','UNIQUE_CARRIER']]\n",
    "    delayFinal.TAIL_NUM = delayFinal.TAIL_NUM.str.strip('N')\n",
    "    delaymfr = pd.merge(delayFinal, joinedAircraftInfo, how='left', on=['TAIL_NUM'])\n",
    "    filteredData.TAIL_NUM = delaymfr.TAIL_NUM\n",
    "    filteredData['AIRCRAFT_YEAR'] = delaymfr.YEAR\n",
    "    filteredData['AIRCRAFT_MFR'] = delaymfr.MFR\n",
    "\n",
    "    # get rid of NAN values\n",
    "    filteredData.dropna(axis = 0, inplace = True)\n",
    "\n",
    "    # get rid of empty year values\n",
    "    filteredData = filteredData[filteredData['AIRCRAFT_YEAR'] != '    ']\n",
    "\n",
    "    # compute age of aircraft\n",
    "    filteredData['AIRCRAFT_AGE'] = filteredData.YEAR.astype(int) - filteredData.AIRCRAFT_YEAR.astype(int)\n",
    "\n",
    "    # now, compress manufacturers to only a small amount of companies\n",
    "    filteredData = compressManufacturers(filteredData)\n",
    "\n",
    "    cleaned_away = 1. - filteredData.count()[0] * 1. / cleaned_away\n",
    "    return filteredData, cleaned_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 201001.zip\n",
      "processing 201001.zip\n",
      "==> cleaned away 0.370071684588%\n",
      "==> added entries: 703\n",
      "reading 201002.zip\n",
      "processing 201002.zip\n",
      "==> cleaned away 0.399608227228%\n",
      "==> added entries: 613\n",
      "reading 201003.zip\n",
      "processing 201003.zip\n",
      "==> cleaned away 0.340909090909%\n",
      "==> added entries: 754\n",
      "reading 201004.zip\n",
      "processing 201004.zip\n",
      "==> cleaned away 0.326858108108%\n",
      "==> added entries: 797\n",
      "reading 201005.zip\n",
      "processing 201005.zip\n",
      "==> cleaned away 0.332497911445%\n",
      "==> added entries: 799\n",
      "reading 201006.zip\n",
      "processing 201006.zip\n",
      "==> cleaned away 0.344913151365%\n",
      "==> added entries: 792\n",
      "reading 201007.zip\n",
      "processing 201007.zip\n",
      "==> cleaned away 0.33932951758%\n",
      "==> added entries: 808\n",
      "reading 201008.zip\n",
      "processing 201008.zip\n",
      "==> cleaned away 0.325119236884%\n",
      "==> added entries: 849\n",
      "reading 201009.zip\n",
      "processing 201009.zip\n",
      "==> cleaned away 0.306782334385%\n",
      "==> added entries: 879\n",
      "reading 201010.zip\n",
      "processing 201010.zip\n",
      "==> cleaned away 0.311588641596%\n",
      "==> added entries: 897\n",
      "reading 201011.zip\n",
      "processing 201011.zip\n",
      "==> cleaned away 0.297448165869%\n",
      "==> added entries: 881\n",
      "reading 201012.zip\n",
      "processing 201012.zip\n",
      "==> cleaned away 0.392313851081%\n",
      "==> added entries: 759\n",
      "reading 201101.zip\n",
      "processing 201101.zip\n",
      "==> cleaned away 0.366095581605%\n",
      "==> added entries: 703\n",
      "reading 201102.zip\n",
      "processing 201102.zip\n",
      "==> cleaned away 0.418957345972%\n",
      "==> added entries: 613\n",
      "reading 201103.zip\n",
      "processing 201103.zip\n",
      "==> cleaned away 0.37684729064%\n",
      "==> added entries: 759\n",
      "reading 201104.zip\n",
      "processing 201104.zip\n",
      "==> cleaned away 0.408390410959%\n",
      "==> added entries: 691\n",
      "reading 201105.zip\n",
      "processing 201105.zip\n",
      "==> cleaned away 0.397993311037%\n",
      "==> added entries: 720\n",
      "reading 201106.zip\n",
      "processing 201106.zip\n",
      "==> cleaned away 0.383064516129%\n",
      "==> added entries: 765\n",
      "reading 201107.zip\n",
      "processing 201107.zip\n",
      "==> cleaned away 0.400796812749%\n",
      "==> added entries: 752\n",
      "reading 201108.zip\n",
      "processing 201108.zip\n",
      "==> cleaned away 0.424940428912%\n",
      "==> added entries: 724\n",
      "reading 201109.zip\n",
      "processing 201109.zip\n",
      "==> cleaned away 0.395388556789%\n",
      "==> added entries: 708\n",
      "reading 201110.zip\n",
      "processing 201110.zip\n",
      "==> cleaned away 0.388841927303%\n",
      "==> added entries: 723\n",
      "reading 201111.zip\n",
      "processing 201111.zip\n",
      "==> cleaned away 0.377201112141%\n",
      "==> added entries: 672\n",
      "reading 201112.zip\n",
      "processing 201112.zip\n",
      "==> cleaned away 0.38816449348%\n",
      "==> added entries: 610\n",
      "reading 201201.zip\n",
      "processing 201201.zip\n",
      "==> cleaned away 0.369942196532%\n",
      "==> added entries: 654\n",
      "reading 201202.zip\n",
      "processing 201202.zip\n",
      "==> cleaned away 0.367952522255%\n",
      "==> added entries: 639\n",
      "reading 201203.zip\n",
      "processing 201203.zip\n",
      "==> cleaned away 0.397634212921%\n",
      "==> added entries: 662\n",
      "reading 201204.zip\n",
      "processing 201204.zip\n",
      "==> cleaned away 0.433085501859%\n",
      "==> added entries: 610\n",
      "reading 201205.zip\n",
      "processing 201205.zip\n",
      "==> cleaned away 0.428443649374%\n",
      "==> added entries: 639\n",
      "reading 201206.zip\n",
      "processing 201206.zip\n",
      "==> cleaned away 0.439143135346%\n",
      "==> added entries: 576\n",
      "reading 201207.zip\n",
      "processing 201207.zip\n",
      "==> cleaned away 0.422287390029%\n",
      "==> added entries: 591\n",
      "reading 201208.zip\n",
      "processing 201208.zip\n",
      "==> cleaned away 0.423713235294%\n",
      "==> added entries: 627\n",
      "reading 201209.zip\n",
      "processing 201209.zip\n",
      "==> cleaned away 0.404021937843%\n",
      "==> added entries: 652\n",
      "reading 201210.zip\n",
      "processing 201210.zip\n",
      "==> cleaned away 0.477130044843%\n",
      "==> added entries: 583\n",
      "reading 201211.zip\n",
      "processing 201211.zip\n",
      "==> cleaned away 0.403157894737%\n",
      "==> added entries: 567\n",
      "reading 201212.zip\n",
      "processing 201212.zip\n",
      "==> cleaned away 0.383233532934%\n",
      "==> added entries: 515\n",
      "reading 201301.zip\n",
      "processing 201301.zip\n",
      "==> cleaned away 0.421221864952%\n",
      "==> added entries: 540\n",
      "reading 201302.zip\n",
      "processing 201302.zip\n",
      "==> cleaned away 0.445205479452%\n",
      "==> added entries: 486\n",
      "reading 201303.zip\n",
      "processing 201303.zip\n",
      "==> cleaned away 0.411764705882%\n",
      "==> added entries: 600\n",
      "reading 201304.zip\n",
      "processing 201304.zip\n",
      "==> cleaned away 0.364051094891%\n",
      "==> added entries: 697\n",
      "reading 201305.zip\n",
      "processing 201305.zip\n",
      "==> cleaned away 0.345454545455%\n",
      "==> added entries: 792\n",
      "reading 201306.zip\n",
      "processing 201306.zip\n",
      "==> cleaned away 0.35781383433%\n",
      "==> added entries: 752\n",
      "reading 201307.zip\n",
      "processing 201307.zip\n",
      "==> cleaned away 0.377833753149%\n",
      "==> added entries: 741\n",
      "reading 201308.zip\n",
      "processing 201308.zip\n",
      "==> cleaned away 0.343333333333%\n",
      "==> added entries: 788\n",
      "reading 201309.zip\n",
      "processing 201309.zip\n",
      "==> cleaned away 0.323404255319%\n",
      "==> added entries: 795\n",
      "reading 201310.zip\n",
      "processing 201310.zip\n",
      "==> cleaned away 0.285601888277%\n",
      "==> added entries: 908\n",
      "reading 201311.zip\n",
      "processing 201311.zip\n",
      "==> cleaned away 0.287892376682%\n",
      "==> added entries: 794\n",
      "reading 201312.zip\n",
      "processing 201312.zip\n",
      "==> cleaned away 0.387939698492%\n",
      "==> added entries: 609\n",
      "reading 201401.zip\n",
      "processing 201401.zip\n",
      "==> cleaned away 0.549528301887%\n",
      "==> added entries: 382\n",
      "reading 201402.zip\n",
      "processing 201402.zip\n",
      "==> cleaned away 0.574332909784%\n",
      "==> added entries: 335\n",
      "reading 201403.zip\n",
      "processing 201403.zip\n",
      "==> cleaned away 0.552222222222%\n",
      "==> added entries: 403\n",
      "reading 201404.zip\n",
      "processing 201404.zip\n",
      "==> cleaned away 0.596273291925%\n",
      "==> added entries: 390\n",
      "reading 201405.zip\n",
      "processing 201405.zip\n",
      "==> cleaned away 0.535839160839%\n",
      "==> added entries: 531\n",
      "reading 201406.zip\n",
      "processing 201406.zip\n",
      "==> cleaned away 0.551813471503%\n",
      "==> added entries: 519\n",
      "reading 201407.zip\n",
      "processing 201407.zip\n",
      "==> cleaned away 0.542372881356%\n",
      "==> added entries: 567\n",
      "reading 201408.zip\n",
      "processing 201408.zip\n",
      "==> cleaned away 0.505957108817%\n",
      "==> added entries: 622\n",
      "reading 201409.zip\n",
      "processing 201409.zip\n",
      "==> cleaned away 0.53112033195%\n",
      "==> added entries: 565\n",
      "reading 201410.zip\n",
      "processing 201410.zip\n",
      "==> cleaned away 0.515488482923%\n",
      "==> added entries: 610\n",
      "reading 201411.zip\n",
      "processing 201411.zip\n",
      "==> cleaned away 0.497363796134%\n",
      "==> added entries: 572\n",
      "reading 201412.zip\n",
      "processing 201412.zip\n",
      "==> cleaned away 0.499559471366%\n",
      "==> added entries: 568\n",
      "CPU times: user 9min 2s, sys: 1min 31s, total: 10min 34s\n",
      "Wall time: 11min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# specify here which cities should be investigated\n",
    "city_from = 'New York, NY'\n",
    "city_to = 'Chicago, IL'\n",
    "\n",
    "# the dataframe to store everything in\n",
    "bigdf = None\n",
    "ca_statistic = []\n",
    "\n",
    "years = ['2010', '2011', '2012', '2013', '2014']\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "for y in years:\n",
    "    for m in months:\n",
    "        \n",
    "        print 'reading {y}{mo}.zip'.format(y=y, mo = m)\n",
    "        z = zipfile.ZipFile('cache/{y}{mo}.zip'.format(y=y, mo = m))\n",
    "        rawData = pd.read_csv(z.open(z.namelist()[0]), low_memory=False)\n",
    "\n",
    "        print 'processing {y}{mo}.zip'.format(y=y, mo = m)\n",
    "        df, ca = processData(rawData)\n",
    "        if bigdf is None:\n",
    "            bigdf = df\n",
    "        else:\n",
    "            bigdf = bigdf.append(df, ignore_index=True)\n",
    "        ca_statistic.append(('{y}{mo}.zip'.format(y=y, mo = m), ca))\n",
    "        print '==> cleaned away {pc}%'.format(pc=ca)\n",
    "        print '==> added entries: {ne}'.format(ne=df.count()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>ARR_DEL15</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>ORIGIN_STATE_NM</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>ORIGIN_WAC</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>AIRCRAFT_YEAR</th>\n",
       "      <th>AIRCRAFT_MFR</th>\n",
       "      <th>AIRCRAFT_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24788</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>-23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>733</td>\n",
       "      <td>New York</td>\n",
       "      <td>737</td>\n",
       "      <td>AA</td>\n",
       "      <td>22</td>\n",
       "      <td>631AA</td>\n",
       "      <td>1990</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24789</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>733</td>\n",
       "      <td>New York</td>\n",
       "      <td>738</td>\n",
       "      <td>AA</td>\n",
       "      <td>22</td>\n",
       "      <td>621AA</td>\n",
       "      <td>1975</td>\n",
       "      <td>CESSNA</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24792</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-01-17</td>\n",
       "      <td>733</td>\n",
       "      <td>New York</td>\n",
       "      <td>730</td>\n",
       "      <td>AA</td>\n",
       "      <td>22</td>\n",
       "      <td>614AA</td>\n",
       "      <td>1989</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24802</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-01-28</td>\n",
       "      <td>733</td>\n",
       "      <td>New York</td>\n",
       "      <td>802</td>\n",
       "      <td>AA</td>\n",
       "      <td>22</td>\n",
       "      <td>630AA</td>\n",
       "      <td>1990</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24808</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>733</td>\n",
       "      <td>New York</td>\n",
       "      <td>803</td>\n",
       "      <td>AA</td>\n",
       "      <td>22</td>\n",
       "      <td>433AA</td>\n",
       "      <td>1987</td>\n",
       "      <td>MCDONNELL DOUGLAS</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index ORIGIN_CITY_NAME  ARR_DEL15  FL_NUM  CANCELLED  ARR_DELAY  MONTH  \\\n",
       "0  24788     New York, NY          0     301          0        -23      1   \n",
       "1  24789     New York, NY          0     301          0        -22      1   \n",
       "2  24792     New York, NY          0     301          0        -30      1   \n",
       "3  24802     New York, NY          0     301          0          2      1   \n",
       "4  24808     New York, NY          0     303          0        -12      1   \n",
       "\n",
       "   DIVERTED  DAY_OF_MONTH DEST_CITY_NAME      ...          FL_DATE  DISTANCE  \\\n",
       "0         0            12    Chicago, IL      ...       2010-01-12       733   \n",
       "1         0            13    Chicago, IL      ...       2010-01-13       733   \n",
       "2         0            17    Chicago, IL      ...       2010-01-17       733   \n",
       "3         0            28    Chicago, IL      ...       2010-01-28       733   \n",
       "4         0             5    Chicago, IL      ...       2010-01-05       733   \n",
       "\n",
       "  ORIGIN_STATE_NM  ARR_TIME  UNIQUE_CARRIER  ORIGIN_WAC  TAIL_NUM  \\\n",
       "0        New York       737              AA          22     631AA   \n",
       "1        New York       738              AA          22     621AA   \n",
       "2        New York       730              AA          22     614AA   \n",
       "3        New York       802              AA          22     630AA   \n",
       "4        New York       803              AA          22     433AA   \n",
       "\n",
       "   AIRCRAFT_YEAR       AIRCRAFT_MFR  AIRCRAFT_AGE  \n",
       "0           1990             BOEING            20  \n",
       "1           1975             CESSNA            35  \n",
       "2           1989             BOEING            21  \n",
       "3           1990             BOEING            20  \n",
       "4           1987  MCDONNELL DOUGLAS            23  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39852"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save to csv\n",
    "bigdf.to_csv('cache/NY_CH_flights.csv')\n",
    "\n",
    "# read from csv\n",
    "bigdf = pd.read_csv('cache/NY_CH_flights.csv')\n",
    "\n",
    "# #entries\n",
    "bigdf.count()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first predictor\n",
    "We want to know for a span of days, which flight we should take. Therefore let's choose the popular date for Christmas returning flights 21.12.2015. As we want to use historical data, let's get first clear what data we have. Is it possible to compare flights over the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_day = 21\n",
    "query_month = 12\n",
    "\n",
    "# how many flights do exist in all years?\n",
    "# y = years[-1]\n",
    "flights = []\n",
    "flightvalues = []\n",
    "for y in years:\n",
    "    query = list(bigdf[bigdf['FL_DATE'] == y+'-'+str(query_month)+'-'+str(query_day)].FL_NUM.astype(int).unique())\n",
    "    flights.append(query)\n",
    "    flightvalues += query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a matrix\n",
    "data_matrix = np.zeros((len(flightvalues), len(years)))\n",
    "# build dict\n",
    "flightdict = dict(zip(flightvalues, np.arange(0, len(flightvalues))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill datamatrix\n",
    "for i in xrange(len(years)):\n",
    "    for j in flights[i]:\n",
    "        data_matrix[flightdict[j], i] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid = np.array([[0, 1, 1], [1, 1, 0], [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x113d48a10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAC5CAYAAAA4eHs5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMAAYQkAYICwBAAwQFgCABjwfytdxrsp1CfUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113676250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(data_matrix, extent=[0,data_matrix.shape[0],0,data_matrix.shape[1] * 5], interpolation='none', cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plot shows, comparison is not really possible. It seems as if airlines change their flight numbers on a yearly basis. Thus we need to come up with another idea.\n",
    "\n",
    "One of the easiest ideas is to average the delay time over each day and refine then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dffordate = bigdf[bigdf.MONTH == query_month]\n",
    "dffordate = dffordate[dffordate.DAY_OF_MONTH == query_day]\n",
    "dffordate.head()\n",
    "\n",
    "def predict_base_model(X):\n",
    "    return np.array([dffordate.ARR_DELAY.mean()]*X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the quality of this model, we use the last year as test set and the previous as train data. The idea is, that we are always interested in predicting the next year somehow. Thus, if the match for 2014 is good, we expect it to be the same for 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build test/train set\n",
    "df_train = dffordate[dffordate.YEAR != int(years[-1])]\n",
    "df_test = dffordate[dffordate.YEAR == int(years[-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df_train.ARR_DELAY\n",
    "X_train = y_train # here dummy\n",
    "y_test = df_test.ARR_DELAY\n",
    "X_test = y_test # here dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the base model, the prediction for 2014 is that we are going to be 27.72minutes late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.728260869565219"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_base_model(X_test)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good did it perform comparing the actual arrival delay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(((y - y_pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.10756003440288"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a linear regression model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One first step is to bin the arrival and departure times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'index', u'ORIGIN_CITY_NAME', u'ARR_DEL15', u'FL_NUM',\n",
       "       u'CANCELLED', u'ARR_DELAY', u'MONTH', u'DIVERTED', u'DAY_OF_MONTH',\n",
       "       u'DEST_CITY_NAME', u'ORIGIN', u'DEP_TIME', u'DEST', u'ARR_DELAY_NEW',\n",
       "       u'DAY_OF_WEEK', u'YEAR', u'AIRLINE_ID', u'QUARTER', u'FL_DATE',\n",
       "       u'DISTANCE', u'ORIGIN_STATE_NM', u'ARR_TIME', u'UNIQUE_CARRIER',\n",
       "       u'ORIGIN_WAC', u'TAIL_NUM', u'AIRCRAFT_YEAR', u'AIRCRAFT_MFR',\n",
       "       u'AIRCRAFT_AGE', u'HOUR_OF_ARR', u'HOUR_OF_DEP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.94 s, sys: 63.9 ms, total: 3.01 s\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigdf['HOUR_OF_ARR'] = 0\n",
    "bigdf['HOUR_OF_DEP'] = 0\n",
    "\n",
    "for index, row in bigdf.iterrows():\n",
    "    bigdf.set_value(index, 'HOUR_OF_ARR', int(row['ARR_TIME']) / 10)\n",
    "    bigdf.set_value(index, 'HOUR_OF_DEP', int(row['DEP_TIME']) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split data into numerical and categorical features\n",
    "numericalFeat = bigdf[['DISTANCE', 'AIRCRAFT_AGE']].astype('float') # Numerical features\n",
    "categoricalFeat = bigdf[['MONTH', 'DAY_OF_MONTH', 'ORIGIN', \n",
    "                    'DEST', 'HOUR_OF_ARR', 'HOUR_OF_DEP', \n",
    "                    'UNIQUE_CARRIER', 'DAY_OF_WEEK', 'AIRCRAFT_MFR']] # Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for the next step, all features need to be encoded as integers --> create lookup Tables!\n",
    "def transformToID(df, col):\n",
    "    vals = df[col].unique()\n",
    "    LookupTable = dict(zip(vals, np.arange(len(vals))))\n",
    "    for key in LookupTable.keys():\n",
    "        df[df[col] == key] = LookupTable[key]\n",
    "    return (LookupTable, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.1 s, sys: 264 ms, total: 26.3 s\n",
      "Wall time: 27 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "mfrDict, categoricalFeat = transformToID(categoricalFeat, 'AIRCRAFT_MFR')\n",
    "originDict, categoricalFeat = transformToID(categoricalFeat, 'ORIGIN')\n",
    "destDict, categoricalFeat = transformToID(categoricalFeat, 'DEST')\n",
    "carrierDict, categoricalFeat = transformToID(categoricalFeat, 'UNIQUE_CARRIER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>HOUR_OF_ARR</th>\n",
       "      <th>HOUR_OF_DEP</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRCRAFT_MFR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY_OF_MONTH ORIGIN DEST  HOUR_OF_ARR  HOUR_OF_DEP UNIQUE_CARRIER  \\\n",
       "0      0             0      0    0            0            0              0   \n",
       "1      1             1      1    1            1            1              1   \n",
       "2      0             0      0    0            0            0              0   \n",
       "3      0             0      0    0            0            0              0   \n",
       "4      2             2      2    2            2            2              2   \n",
       "\n",
       "   DAY_OF_WEEK AIRCRAFT_MFR  \n",
       "0            0            0  \n",
       "1            1            1  \n",
       "2            0            0  \n",
       "3            0            0  \n",
       "4            2            2  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricalFeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>AIRCRAFT_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>733</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>733</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>733</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>733</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DISTANCE  AIRCRAFT_AGE\n",
       "0       733            20\n",
       "1       733            35\n",
       "2       733            21\n",
       "3       733            20\n",
       "4       733            23"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericalFeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode categorical variables as binary ones\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder() \n",
    "categoricals_encoded = encoder.fit_transform(categoricalFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert numerical features to sparse matrix\n",
    "from scipy import sparse\n",
    "numericals_sparse = sparse.csr_matrix(numericalFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get data matrix & response variable\n",
    "X_all = sparse.hstack((numericals_sparse, categoricals_encoded))\n",
    "y_all = bigdf['ARR_DELAY'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct test/train set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# before starting the regression, numerical features need to be standardized!\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_numericals = X_train[:, 0:3].toarray()\n",
    "X_test_numericals = X_test[:, 0:3].toarray()\n",
    "\n",
    "# use sklearn tools...\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train_numericals) # get std/mean from train set\n",
    "X_train_numericals = sparse.csr_matrix(scaler.transform(X_train_numericals)) \n",
    "X_test_numericals = sparse.csr_matrix(scaler.transform(X_test_numericals))\n",
    "\n",
    "# update sets\n",
    "X_train[:, 0:3] = X_train_numericals\n",
    "X_test[:, 0:3] = X_test_numericals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use ridge regression (i.e. Gaussian prior) and vary the lambda parameter using Grid search\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "SGD_params = {'alpha': 10.0 ** -np.arange(1,8)}\n",
    "SGD_model = GridSearchCV(SGDRegressor(random_state = 42), \\\n",
    "                         SGD_params, scoring = 'mean_absolute_error', cv = 6) # cross validate 6 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 s, sys: 8.95 ms, total: 1.31 s\n",
      "Wall time: 1.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
       "       random_state=42, shuffle=True, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e-01,   1.00000e-02,   1.00000e-03,   1.00000e-04,\n",
       "         1.00000e-05,   1.00000e-06,   1.00000e-07])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
       "       scoring='mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train the model, this might take some time...\n",
    "SGD_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.366834575559849"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = SGD_model.predict(X_test)\n",
    "rmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS based linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "\n",
    "# use all CPU power!\n",
    "clf = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# fit the model!\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.366834575559849"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = SGD_model.predict(X_test)\n",
    "rmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04326227,  0.58407066, -0.44106357, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.68271074, -0.87076288, -0.44106357, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.04326227,  0.0706    , -0.44106357, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.04326227,  0.32733533, -0.44106357, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.04326227, -0.27171377, -0.44106357, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.04326227, -0.27171377, -0.44106357, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.19928342,  0.9509056 ,  2.06800045, -0.24940167, -0.66548389,\n",
       "       -0.97159704,  0.20346512,  1.21962386, -0.05589239,  0.60478787,\n",
       "        0.16326631, -0.06471128, -1.97449098, -0.65260946,  0.04920967,\n",
       "       -3.74946182,  1.0992649 ,  0.29794088,  0.66053055,  0.11732689,\n",
       "       -0.24940167, -0.66548389, -0.97159704,  0.20346512,  1.21962386,\n",
       "       -0.05589239,  0.60478787,  0.16326631, -0.06471128, -1.97449098,\n",
       "       -0.65260946,  0.04920967, -3.74946182,  1.0992649 ,  0.29794088,\n",
       "        0.66053055,  0.11732689, -0.24940167, -0.66548389, -0.97159704,\n",
       "        0.20346512,  1.21962386, -0.05589239,  0.60478787,  0.16326631,\n",
       "       -0.06471128, -1.97449098, -0.65260946,  0.04920967, -3.74946182,\n",
       "        1.0992649 ,  0.29794088,  0.66053055,  0.11732689, -0.24940167,\n",
       "       -0.66548389, -0.97159704,  0.20346512,  1.21962386, -0.05589239,\n",
       "        0.60478787,  0.16326631, -0.06471128, -1.97449098, -0.65260946,\n",
       "        0.04920967, -3.74946182,  1.0992649 ,  0.29794088,  0.66053055,\n",
       "        0.11732689, -0.24940167, -0.66548389, -0.97159704,  0.20346512,\n",
       "        1.21962386, -0.05589239,  0.60478787,  0.16326631, -0.06471128,\n",
       "       -1.97449098, -0.65260946,  0.04920967, -3.74946182,  1.0992649 ,\n",
       "        0.29794088,  0.66053055,  0.11732689, -0.24940167, -0.66548389,\n",
       "       -0.97159704,  0.20346512,  1.21962386, -0.05589239,  0.60478787,\n",
       "        0.16326631, -0.06471128, -1.97449098, -0.65260946,  0.04920967,\n",
       "       -3.74946182,  1.0992649 ,  0.29794088,  0.66053055,  0.11732689,\n",
       "       -0.24940167, -0.66548389, -0.97159704,  0.20346512,  1.21962386,\n",
       "       -0.05589239,  0.60478787,  0.16326631, -0.06471128, -1.97449098,\n",
       "       -0.65260946,  0.04920967, -3.74946182,  1.0992649 ,  0.29794088,\n",
       "        0.66053055,  0.11732689, -0.24940167, -0.66548389, -0.97159704,\n",
       "        0.20346512,  1.21962386, -0.05589239,  0.60478787,  0.16326631,\n",
       "       -0.06471128, -1.97449098, -0.65260946,  0.04920967, -3.74946182,\n",
       "        1.0992649 ,  0.29794088,  0.66053055,  0.11732689, -0.24940167,\n",
       "       -0.66548389, -0.97159704,  0.20346512,  1.21962386, -0.05589239,\n",
       "        0.60478787,  0.16326631, -0.06471128, -1.97449098, -0.65260946,\n",
       "        0.04920967, -3.74946182,  1.0992649 ,  0.29794088,  0.66053055])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
