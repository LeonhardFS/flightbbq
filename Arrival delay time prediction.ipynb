{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrival delay time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import required modules for prediction tasks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import zipfile\n",
    "import StringIO\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import requests, zipfile, StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we want to develop a model to predict arrival delay time for flights between two cities. As our primary example we investigate flights from New York(all airports) to Chicago(all airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given a list of column labels remove all columns that are in the df\n",
    "def filterDF(df, cols):\n",
    "    colsToKeep = list(set(df.columns) & set(cols))\n",
    "    \n",
    "    return df[colsToKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given a dataframe this function groups all manufacturers into one category whose market share is low (default: 1%)\n",
    "# also groups together some companies\n",
    "def compressManufacturers(df, percentage=1.):\n",
    "    df['AIRCRAFT_MFR'] = df['AIRCRAFT_MFR'].map(lambda x: x.strip())\n",
    "    mfr_stats = df['AIRCRAFT_MFR'].value_counts()\n",
    "    \n",
    "    market_share = mfr_stats.values * 100. / np.sum(mfr_stats.values)\n",
    "    idxs = np.where(market_share < percentage)\n",
    "    names = np.array([el for el in list(mfr_stats.keys())])\n",
    "\n",
    "    # get labels for small manufacturers\n",
    "    smallMFR = names[idxs]\n",
    "\n",
    "    # perform merging for the big companies\n",
    "    # Douglas airplanes\n",
    "    df.loc[df['AIRCRAFT_MFR'] == 'MCDONNELL DOUGLAS AIRCRAFT CO', 'AIRCRAFT_MFR'] = 'MCDONNELL DOUGLAS'\n",
    "    df.loc[df['AIRCRAFT_MFR'] == 'MCDONNELL DOUGLAS CORPORATION', 'AIRCRAFT_MFR'] = 'MCDONNELL DOUGLAS'\n",
    "    df.loc[df['AIRCRAFT_MFR'] == 'MCDONNELL DOUGLAS CORPORATION', 'AIRCRAFT_MFR'] = 'DOUGLAS'\n",
    "\n",
    "    # Embraer\n",
    "    df.loc[df['AIRCRAFT_MFR'] == 'EMBRAER S A', 'AIRCRAFT_MFR'] = 'EMBRAER'\n",
    "\n",
    "    # Airbus\n",
    "    df.loc[df['AIRCRAFT_MFR'] == 'AIRBUS INDUSTRIE', 'AIRCRAFT_MFR'] = 'AIRBUS'\n",
    "\n",
    "    # the small manufacturers\n",
    "    for name in smallMFR:\n",
    "        df.loc[df['AIRCRAFT_MFR'] == name, 'AIRCRAFT_MFR'] = 'SMALL'\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get external aircraft data load additional data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = zipfile.ZipFile('externalData/AircraftInformation.zip')\n",
    "df_master  = pd.DataFrame.from_csv(z.open('MASTER.txt'))\n",
    "df_aircrafts  = pd.DataFrame.from_csv(z.open('ACFTREF.txt'))\n",
    "master = df_master[['MFR MDL CODE', 'YEAR MFR']].reset_index()\n",
    "aircrafts = df_aircrafts['MFR'].reset_index()\n",
    "master.columns = ['TAIL_NUM', 'CODE', 'YEAR']\n",
    "aircrafts.columns = ['CODE', 'MFR']\n",
    "joinedAircraftInfo = pd.merge(master, aircrafts, how='left', on='CODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joinedAircraftInfo.TAIL_NUM = joinedAircraftInfo.TAIL_NUM.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# possible fields\n",
    "# [u'YEAR', u'QUARTER', u'MONTH', u'DAY_OF_MONTH', u'DAY_OF_WEEK',\n",
    "#        u'FL_DATE', u'UNIQUE_CARRIER', u'AIRLINE_ID', u'CARRIER', u'TAIL_NUM',\n",
    "#        u'FL_NUM', u'ORIGIN', u'ORIGIN_CITY_NAME', u'ORIGIN_STATE_ABR',\n",
    "#        u'ORIGIN_STATE_FIPS', u'ORIGIN_STATE_NM', u'ORIGIN_WAC', u'DEST',\n",
    "#        u'DEST_CITY_NAME', u'DEST_STATE_ABR', u'DEST_STATE_FIPS',\n",
    "#        u'DEST_STATE_NM', u'DEST_WAC', u'CRS_DEP_TIME', u'DEP_TIME',\n",
    "#        u'DEP_DELAY', u'DEP_DELAY_NEW', u'DEP_DEL15', u'DEP_DELAY_GROUP',\n",
    "#        u'DEP_TIME_BLK', u'TAXI_OUT', u'WHEELS_OFF', u'WHEELS_ON', u'TAXI_IN',\n",
    "#        u'CRS_ARR_TIME', u'ARR_TIME', u'ARR_DELAY', u'ARR_DELAY_NEW',\n",
    "#        u'ARR_DEL15', u'ARR_DELAY_GROUP', u'ARR_TIME_BLK', u'CANCELLED',\n",
    "#        u'CANCELLATION_CODE', u'DIVERTED', u'CRS_ELAPSED_TIME',\n",
    "#        u'ACTUAL_ELAPSED_TIME', u'AIR_TIME', u'FLIGHTS', u'DISTANCE',\n",
    "#        u'DISTANCE_GROUP', u'CARRIER_DELAY', u'WEATHER_DELAY', u'NAS_DELAY',\n",
    "#        u'SECURITY_DELAY', u'LATE_AIRCRAFT_DELAY', u'FIRST_DEP_TIME',\n",
    "#        u'TOTAL_ADD_GTIME', u'LONGEST_ADD_GTIME', u'DIV_AIRPORT_LANDINGS',\n",
    "#        u'DIV_REACHED_DEST', u'DIV_ACTUAL_ELAPSED_TIME', u'DIV_ARR_DELAY',\n",
    "#        u'DIV_DISTANCE', u'DIV1_AIRPORT', u'DIV1_WHEELS_ON',\n",
    "#        u'DIV1_TOTAL_GTIME', u'DIV1_LONGEST_GTIME', u'DIV1_WHEELS_OFF',\n",
    "#        u'DIV1_TAIL_NUM', u'DIV2_AIRPORT', u'DIV2_WHEELS_ON',\n",
    "#        u'DIV2_TOTAL_GTIME', u'DIV2_LONGEST_GTIME', u'DIV2_WHEELS_OFF',\n",
    "#        u'DIV2_TAIL_NUM', u'DIV3_AIRPORT', u'DIV3_WHEELS_ON',\n",
    "#        u'DIV3_TOTAL_GTIME', u'DIV3_LONGEST_GTIME', u'DIV3_WHEELS_OFF',\n",
    "#        u'DIV3_TAIL_NUM', u'DIV4_AIRPORT', u'DIV4_WHEELS_ON',\n",
    "#        u'DIV4_TOTAL_GTIME', u'DIV4_LONGEST_GTIME', u'DIV4_WHEELS_OFF',\n",
    "#        u'DIV4_TAIL_NUM', u'DIV5_AIRPORT', u'DIV5_WHEELS_ON',\n",
    "#        u'DIV5_TOTAL_GTIME', u'DIV5_LONGEST_GTIME', u'DIV5_WHEELS_OFF',\n",
    "#        u'DIV5_TAIL_NUM', u'Unnamed: 93', u'AIRCRAFT_YEAR', u'AIRCRAFT_AGE',\n",
    "#        u'AIRCRAFT_MFR']\n",
    "\n",
    "# define here which columns to include in the data extraction process\n",
    "columnsToUse = [u'YEAR', u'QUARTER', u'MONTH', u'DAY_OF_MONTH', u'DAY_OF_WEEK',\n",
    "       u'FL_DATE', u'UNIQUE_CARRIER', u'AIRLINE_ID',u'TAIL_NUM',\n",
    "       u'FL_NUM', u'ORIGIN', u'ORIGIN_CITY_NAME',\n",
    "       u'ORIGIN_STATE_NM', u'ORIGIN_WAC', u'DEST',\n",
    "       u'DEST_CITY_NAME',u'ARR_DELAY', u'ARR_DELAY_NEW',\n",
    "       u'ARR_DEL15', u'CANCELLED', u'DIVERTED', u'DISTANCE',u'AIRCRAFT_YEAR', u'AIRCRAFT_AGE',\n",
    "       u'AIRCRAFT_MFR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given the raw BTS data, this function filters it and returns \n",
    "# a filtered version along with how much percent has been removed\n",
    "def processData(rawData):\n",
    "    # filter for city first\n",
    "    filteredData = rawData[(rawData.ORIGIN_CITY_NAME == city_from) & (rawData.DEST_CITY_NAME == city_to)]\n",
    "\n",
    "    # this is how much percent have been cleaned away!\n",
    "    cleaned_away = filteredData.count()[0]\n",
    "\n",
    "    # remove columns that are not needed for the model\n",
    "    filteredData = filterDF(filteredData, columnsToUse)\n",
    "    filteredData.reset_index(inplace=True)\n",
    "\n",
    "    # perform as next step join to amend information by aircraftdata\n",
    "    delayFinal = filteredData[['TAIL_NUM','UNIQUE_CARRIER']]\n",
    "    delayFinal.TAIL_NUM = delayFinal.TAIL_NUM.str.strip('N')\n",
    "    delaymfr = pd.merge(delayFinal, joinedAircraftInfo, how='left', on=['TAIL_NUM'])\n",
    "    filteredData.TAIL_NUM = delaymfr.TAIL_NUM\n",
    "    filteredData['AIRCRAFT_YEAR'] = delaymfr.YEAR\n",
    "    filteredData['AIRCRAFT_MFR'] = delaymfr.MFR\n",
    "\n",
    "    # get rid of NAN values\n",
    "    filteredData.dropna(axis = 0, inplace = True)\n",
    "\n",
    "    # get rid of empty year values\n",
    "    filteredData = filteredData[filteredData['AIRCRAFT_YEAR'] != '    ']\n",
    "\n",
    "    # compute age of aircraft\n",
    "    filteredData['AIRCRAFT_AGE'] = filteredData.YEAR.astype(int) - filteredData.AIRCRAFT_YEAR.astype(int)\n",
    "\n",
    "    # now, compress manufacturers to only a small amount of companies\n",
    "    filteredData = compressManufacturers(filteredData)\n",
    "\n",
    "    cleaned_away = 1. - filteredData.count()[0] * 1. / cleaned_away\n",
    "    return filteredData, cleaned_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 201001.zip\n",
      "processing 201001.zip\n",
      "==> cleaned away 0.370071684588%\n",
      "==> added entries: 703\n",
      "reading 201002.zip\n",
      "processing 201002.zip\n",
      "==> cleaned away 0.399608227228%\n",
      "==> added entries: 613\n",
      "reading 201003.zip\n",
      "processing 201003.zip\n",
      "==> cleaned away 0.340909090909%\n",
      "==> added entries: 754\n",
      "reading 201004.zip\n",
      "processing 201004.zip\n",
      "==> cleaned away 0.326858108108%\n",
      "==> added entries: 797\n",
      "reading 201005.zip\n",
      "processing 201005.zip\n",
      "==> cleaned away 0.332497911445%\n",
      "==> added entries: 799\n",
      "reading 201006.zip\n",
      "processing 201006.zip\n",
      "==> cleaned away 0.344913151365%\n",
      "==> added entries: 792\n",
      "reading 201007.zip\n",
      "processing 201007.zip\n",
      "==> cleaned away 0.33932951758%\n",
      "==> added entries: 808\n",
      "reading 201008.zip\n",
      "processing 201008.zip\n",
      "==> cleaned away 0.325119236884%\n",
      "==> added entries: 849\n",
      "reading 201009.zip\n",
      "processing 201009.zip\n",
      "==> cleaned away 0.306782334385%\n",
      "==> added entries: 879\n",
      "reading 201010.zip\n",
      "processing 201010.zip\n",
      "==> cleaned away 0.311588641596%\n",
      "==> added entries: 897\n",
      "reading 201011.zip\n",
      "processing 201011.zip\n",
      "==> cleaned away 0.297448165869%\n",
      "==> added entries: 881\n",
      "reading 201012.zip\n",
      "processing 201012.zip\n",
      "==> cleaned away 0.392313851081%\n",
      "==> added entries: 759\n",
      "reading 201101.zip\n",
      "processing 201101.zip\n",
      "==> cleaned away 0.366095581605%\n",
      "==> added entries: 703\n",
      "reading 201102.zip\n",
      "processing 201102.zip\n",
      "==> cleaned away 0.418957345972%\n",
      "==> added entries: 613\n",
      "reading 201103.zip\n",
      "processing 201103.zip\n",
      "==> cleaned away 0.37684729064%\n",
      "==> added entries: 759\n",
      "reading 201104.zip\n",
      "processing 201104.zip\n",
      "==> cleaned away 0.408390410959%\n",
      "==> added entries: 691\n",
      "reading 201105.zip\n",
      "processing 201105.zip\n",
      "==> cleaned away 0.397993311037%\n",
      "==> added entries: 720\n",
      "reading 201106.zip\n",
      "processing 201106.zip\n",
      "==> cleaned away 0.383064516129%\n",
      "==> added entries: 765\n",
      "reading 201107.zip\n",
      "processing 201107.zip\n",
      "==> cleaned away 0.400796812749%\n",
      "==> added entries: 752\n",
      "reading 201108.zip\n",
      "processing 201108.zip\n",
      "==> cleaned away 0.424940428912%\n",
      "==> added entries: 724\n",
      "reading 201109.zip\n",
      "processing 201109.zip\n",
      "==> cleaned away 0.395388556789%\n",
      "==> added entries: 708\n",
      "reading 201110.zip\n",
      "processing 201110.zip\n",
      "==> cleaned away 0.388841927303%\n",
      "==> added entries: 723\n",
      "reading 201111.zip\n",
      "processing 201111.zip\n",
      "==> cleaned away 0.377201112141%\n",
      "==> added entries: 672\n",
      "reading 201112.zip\n",
      "processing 201112.zip\n",
      "==> cleaned away 0.38816449348%\n",
      "==> added entries: 610\n",
      "reading 201201.zip\n",
      "processing 201201.zip\n",
      "==> cleaned away 0.369942196532%\n",
      "==> added entries: 654\n",
      "reading 201202.zip\n",
      "processing 201202.zip\n",
      "==> cleaned away 0.367952522255%\n",
      "==> added entries: 639\n",
      "reading 201203.zip\n",
      "processing 201203.zip\n",
      "==> cleaned away 0.397634212921%\n",
      "==> added entries: 662\n",
      "reading 201204.zip\n",
      "processing 201204.zip\n",
      "==> cleaned away 0.433085501859%\n",
      "==> added entries: 610\n",
      "reading 201205.zip\n",
      "processing 201205.zip\n",
      "==> cleaned away 0.428443649374%\n",
      "==> added entries: 639\n",
      "reading 201206.zip\n",
      "processing 201206.zip\n",
      "==> cleaned away 0.439143135346%\n",
      "==> added entries: 576\n",
      "reading 201207.zip\n",
      "processing 201207.zip\n",
      "==> cleaned away 0.422287390029%\n",
      "==> added entries: 591\n",
      "reading 201208.zip\n",
      "processing 201208.zip\n",
      "==> cleaned away 0.423713235294%\n",
      "==> added entries: 627\n",
      "reading 201209.zip\n",
      "processing 201209.zip\n",
      "==> cleaned away 0.404021937843%\n",
      "==> added entries: 652\n",
      "reading 201210.zip\n",
      "processing 201210.zip\n",
      "==> cleaned away 0.477130044843%\n",
      "==> added entries: 583\n",
      "reading 201211.zip\n",
      "processing 201211.zip\n",
      "==> cleaned away 0.403157894737%\n",
      "==> added entries: 567\n",
      "reading 201212.zip\n",
      "processing 201212.zip\n",
      "==> cleaned away 0.383233532934%\n",
      "==> added entries: 515\n",
      "reading 201301.zip\n",
      "processing 201301.zip\n",
      "==> cleaned away 0.421221864952%\n",
      "==> added entries: 540\n",
      "reading 201302.zip\n",
      "processing 201302.zip\n",
      "==> cleaned away 0.445205479452%\n",
      "==> added entries: 486\n",
      "reading 201303.zip\n",
      "processing 201303.zip\n",
      "==> cleaned away 0.411764705882%\n",
      "==> added entries: 600\n",
      "reading 201304.zip\n",
      "processing 201304.zip\n",
      "==> cleaned away 0.364051094891%\n",
      "==> added entries: 697\n",
      "reading 201305.zip\n",
      "processing 201305.zip\n",
      "==> cleaned away 0.345454545455%\n",
      "==> added entries: 792\n",
      "reading 201306.zip\n",
      "processing 201306.zip\n",
      "==> cleaned away 0.35781383433%\n",
      "==> added entries: 752\n",
      "reading 201307.zip\n",
      "processing 201307.zip\n",
      "==> cleaned away 0.377833753149%\n",
      "==> added entries: 741\n",
      "reading 201308.zip\n",
      "processing 201308.zip\n",
      "==> cleaned away 0.343333333333%\n",
      "==> added entries: 788\n",
      "reading 201309.zip\n",
      "processing 201309.zip\n",
      "==> cleaned away 0.323404255319%\n",
      "==> added entries: 795\n",
      "reading 201310.zip\n",
      "processing 201310.zip\n",
      "==> cleaned away 0.285601888277%\n",
      "==> added entries: 908\n",
      "reading 201311.zip\n",
      "processing 201311.zip\n",
      "==> cleaned away 0.287892376682%\n",
      "==> added entries: 794\n",
      "reading 201312.zip\n",
      "processing 201312.zip\n",
      "==> cleaned away 0.387939698492%\n",
      "==> added entries: 609\n",
      "reading 201401.zip\n",
      "processing 201401.zip\n",
      "==> cleaned away 0.549528301887%\n",
      "==> added entries: 382\n",
      "reading 201402.zip\n",
      "processing 201402.zip\n",
      "==> cleaned away 0.574332909784%\n",
      "==> added entries: 335\n",
      "reading 201403.zip\n",
      "processing 201403.zip\n",
      "==> cleaned away 0.552222222222%\n",
      "==> added entries: 403\n",
      "reading 201404.zip\n",
      "processing 201404.zip\n",
      "==> cleaned away 0.596273291925%\n",
      "==> added entries: 390\n",
      "reading 201405.zip\n",
      "processing 201405.zip\n",
      "==> cleaned away 0.535839160839%\n",
      "==> added entries: 531\n",
      "reading 201406.zip\n",
      "processing 201406.zip\n",
      "==> cleaned away 0.551813471503%\n",
      "==> added entries: 519\n",
      "reading 201407.zip\n",
      "processing 201407.zip\n",
      "==> cleaned away 0.542372881356%\n",
      "==> added entries: 567\n",
      "reading 201408.zip\n",
      "processing 201408.zip\n",
      "==> cleaned away 0.505957108817%\n",
      "==> added entries: 622\n",
      "reading 201409.zip\n",
      "processing 201409.zip\n",
      "==> cleaned away 0.53112033195%\n",
      "==> added entries: 565\n",
      "reading 201410.zip\n",
      "processing 201410.zip\n",
      "==> cleaned away 0.515488482923%\n",
      "==> added entries: 610\n",
      "reading 201411.zip\n",
      "processing 201411.zip\n",
      "==> cleaned away 0.497363796134%\n",
      "==> added entries: 572\n",
      "reading 201412.zip\n",
      "processing 201412.zip\n",
      "==> cleaned away 0.499559471366%\n",
      "==> added entries: 568\n",
      "CPU times: user 8min 35s, sys: 1min 24s, total: 9min 59s\n",
      "Wall time: 10min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# specify here which cities should be investigated\n",
    "city_from = 'New York, NY'\n",
    "city_to = 'Chicago, IL'\n",
    "\n",
    "# the dataframe to store everything in\n",
    "bigdf = None\n",
    "ca_statistic = []\n",
    "\n",
    "years = ['2010', '2011', '2012', '2013', '2014']\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "for y in years:\n",
    "    for m in months:\n",
    "        \n",
    "        print 'reading {y}{mo}.zip'.format(y=y, mo = m)\n",
    "        z = zipfile.ZipFile('cache/{y}{mo}.zip'.format(y=y, mo = m))\n",
    "        rawData = pd.read_csv(z.open(z.namelist()[0]), low_memory=False)\n",
    "\n",
    "        print 'processing {y}{mo}.zip'.format(y=y, mo = m)\n",
    "        df, ca = processData(rawData)\n",
    "        if bigdf is None:\n",
    "            bigdf = df\n",
    "        else:\n",
    "            bigdf = bigdf.append(df, ignore_index=True)\n",
    "        ca_statistic.append(('{y}{mo}.zip'.format(y=y, mo = m), ca))\n",
    "        print '==> cleaned away {pc}%'.format(pc=ca)\n",
    "        print '==> added entries: {ne}'.format(ne=df.count()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>ARR_DEL15</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>AIRLINE_ID</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>...</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>ORIGIN_STATE_NM</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>ORIGIN_WAC</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>AIRCRAFT_YEAR</th>\n",
       "      <th>AIRCRAFT_MFR</th>\n",
       "      <th>AIRCRAFT_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24788</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>19805</td>\n",
       "      <td>-23</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>733</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>22</td>\n",
       "      <td>631AA</td>\n",
       "      <td>1990</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24789</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>19805</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>733</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>22</td>\n",
       "      <td>621AA</td>\n",
       "      <td>1975</td>\n",
       "      <td>CESSNA</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24792</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>19805</td>\n",
       "      <td>-30</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-01-17</td>\n",
       "      <td>733</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>22</td>\n",
       "      <td>614AA</td>\n",
       "      <td>1989</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24802</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>19805</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-01-28</td>\n",
       "      <td>733</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>22</td>\n",
       "      <td>630AA</td>\n",
       "      <td>1990</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24808</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>19805</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>733</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>22</td>\n",
       "      <td>433AA</td>\n",
       "      <td>1987</td>\n",
       "      <td>MCDONNELL DOUGLAS</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index ORIGIN_CITY_NAME  ARR_DEL15  FL_NUM  AIRLINE_ID  ARR_DELAY  DIVERTED  \\\n",
       "0  24788     New York, NY          0     301       19805        -23         0   \n",
       "1  24789     New York, NY          0     301       19805        -22         0   \n",
       "2  24792     New York, NY          0     301       19805        -30         0   \n",
       "3  24802     New York, NY          0     301       19805          2         0   \n",
       "4  24808     New York, NY          0     303       19805        -12         0   \n",
       "\n",
       "   DAY_OF_MONTH DEST_CITY_NAME ORIGIN      ...          FL_DATE  DISTANCE  \\\n",
       "0            12    Chicago, IL    LGA      ...       2010-01-12       733   \n",
       "1            13    Chicago, IL    LGA      ...       2010-01-13       733   \n",
       "2            17    Chicago, IL    LGA      ...       2010-01-17       733   \n",
       "3            28    Chicago, IL    LGA      ...       2010-01-28       733   \n",
       "4             5    Chicago, IL    LGA      ...       2010-01-05       733   \n",
       "\n",
       "   ORIGIN_STATE_NM  MONTH  UNIQUE_CARRIER  ORIGIN_WAC TAIL_NUM  AIRCRAFT_YEAR  \\\n",
       "0         New York      1              AA          22    631AA           1990   \n",
       "1         New York      1              AA          22    621AA           1975   \n",
       "2         New York      1              AA          22    614AA           1989   \n",
       "3         New York      1              AA          22    630AA           1990   \n",
       "4         New York      1              AA          22    433AA           1987   \n",
       "\n",
       "        AIRCRAFT_MFR  AIRCRAFT_AGE  \n",
       "0             BOEING            20  \n",
       "1             CESSNA            35  \n",
       "2             BOEING            21  \n",
       "3             BOEING            20  \n",
       "4  MCDONNELL DOUGLAS            23  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39852"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save to csv\n",
    "bigdf.to_csv('cache/NY_CH_flights.csv')\n",
    "# #entries\n",
    "bigdf.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
