{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Delay Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import required modules for prediction tasks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data acquisition and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reads all predefined months for a year and merge into one data frame\n",
    "rawData2014 = pd.DataFrame.from_csv('cache/predictionData/complete2014Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print rawData2014.columns\n",
    "rawData2014.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When cleaning the data set, we have to remove the following entries:\n",
    "\n",
    "- flights that have been cancelled or diverted. We focus on predicting the delay. As a result, we also remove the columns associated with diverted flights.\n",
    "- colmuns that give the answer. This is the case of many colmuns related to the arrival of the plane\n",
    "- rows where a value is missing\n",
    "\n",
    "Note that data points have to be cleaned in this order because most flights have empty entries for the 'diverted' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#entries to be dropped in the analysis\n",
    "columns_dropped = ['index', 'TAIL_NUM', 'FL_NUM', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF', \\\n",
    "                   'WHEELS_ON', 'TAXI_IN', 'ARR_TIME', 'CANCELLED', 'CANCELLATION_CODE', 'AIR_TIME', \\\n",
    "                   'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(data, list_col):\n",
    "    ''' \n",
    "    Creates a dataset by excluding undesirable columns\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       Flight dataframe  \n",
    "\n",
    "    list_col: <list 'string'>\n",
    "        Comumns to exclude from the data set\n",
    "    '''\n",
    "    \n",
    "    data.drop(data[data.CANCELLED == 0].index, inplace=True)\n",
    "    data.drop(list_col, axis=1, inplace=True)\n",
    "    data.dropna(axis = 0, inplace = True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data2014 = clean(rawData2014.copy(), columns_dropped)\n",
    "print data2014.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# save the data to avoid computing them again\n",
    "file_path = \"cache/predictionData/predictionData2014.csv\"\n",
    "data2014.to_csv(path_or_buf= file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# recover data2014 from cache/predictionData folder\n",
    "file_path = \"cache/predictionData/predictionData2014.csv\"\n",
    "data2014 = pd.read_csv(file_path)\n",
    "data2014.drop('Unnamed: 0', axis= 1, inplace = True)\n",
    "data2014.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test that clean did the job\n",
    "print \"size of raw data set: \", len(rawData2014)\n",
    "print \"number of cancelled: \", len(rawData2014[(rawData2014.CANCELLED == 1)])\n",
    "print \"size of data set: \", len(data2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add an example that we will follow all along. The example looks a ta flight from New York to Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>AIRCRAFT_YEAR</th>\n",
       "      <th>AIRCRAFT_MFR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>700</td>\n",
       "      <td>850</td>\n",
       "      <td>-17</td>\n",
       "      <td>733</td>\n",
       "      <td>1991</td>\n",
       "      <td>MCDONNELL DOUGLAS</td>\n",
       "      <td>40.766667</td>\n",
       "      <td>-73.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>700</td>\n",
       "      <td>850</td>\n",
       "      <td>32</td>\n",
       "      <td>733</td>\n",
       "      <td>2007</td>\n",
       "      <td>FRIEDEMANN JON</td>\n",
       "      <td>40.766667</td>\n",
       "      <td>-73.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>700</td>\n",
       "      <td>850</td>\n",
       "      <td>11</td>\n",
       "      <td>733</td>\n",
       "      <td>2007</td>\n",
       "      <td>FRIEDEMANN JON</td>\n",
       "      <td>40.766667</td>\n",
       "      <td>-73.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FL_DATE UNIQUE_CARRIER ORIGIN DEST  CRS_DEP_TIME  CRS_ARR_TIME  \\\n",
       "2033  2014-01-01             AA    LGA  ORD           700           850   \n",
       "2034  2014-01-04             AA    LGA  ORD           700           850   \n",
       "2035  2014-01-05             AA    LGA  ORD           700           850   \n",
       "\n",
       "      ARR_DELAY  DISTANCE AIRCRAFT_YEAR                    AIRCRAFT_MFR  \\\n",
       "2033        -17       733          1991  MCDONNELL DOUGLAS                \n",
       "2034         32       733          2007  FRIEDEMANN JON                   \n",
       "2035         11       733          2007  FRIEDEMANN JON                   \n",
       "\n",
       "            LAT       LONG  \n",
       "2033  40.766667 -73.866667  \n",
       "2034  40.766667 -73.866667  \n",
       "2035  40.766667 -73.866667  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dexample = data2014[data2014.DEST == 'ORD'][(data2014.ORIGIN == 'JFK')  | (data2014.ORIGIN == 'LGA') | \\\n",
    "                                              (data2014.ORIGIN == 'EWR')].copy()\n",
    "\n",
    "dexample.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has more than 4 millions entries, which makes any data manipulation extremely costly - let alone model fitting. We will therefore make some restrictions on the airports and the airlines considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNIQUE_CARRIER\n",
       "AA    137960\n",
       "AS    157312\n",
       "B6    225303\n",
       "DL    644768\n",
       "EV    616920\n",
       "F9     81758\n",
       "FL     69486\n",
       "HA     73370\n",
       "MQ      2995\n",
       "OO    586067\n",
       "UA    471093\n",
       "US    381688\n",
       "VX     57056\n",
       "WN    597821\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2014.groupby('UNIQUE_CARRIER').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in the carrier that operates from New York to Chicago. Looking at the table, we also notice that Atlantic Southeast Airlines (airline code EV) is only marginally present. So we drop it from the list of carriers we will study in addition to the other carriers that do not operate on the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNIQUE_CARRIER\n",
       "AA     126\n",
       "B6     955\n",
       "EV       2\n",
       "OO     191\n",
       "UA    6821\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dexample.groupby('UNIQUE_CARRIER').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def restrict_carrier(data, droplist):\n",
    "    ''' \n",
    "    Drop carriers from the data set.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       dataframe  \n",
    "\n",
    "    droplist: <list 'string'>\n",
    "        List of carriers to be droppped\n",
    "    '''        \n",
    "    \n",
    "    for item in droplist:\n",
    "        data.drop(data[data.UNIQUE_CARRIER == item].index, inplace= True)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points 1420423\n",
      "airlines set(['AA', 'OO', 'B6', 'UA'])\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "drop_airline = [ 'AS','DL', 'EV', 'F9', 'FL', 'HA', 'MQ', 'US', 'VX', 'WN']\n",
    "restrict_carrier(data2014, drop_airline)\n",
    "print \"number of points\", len(data2014)\n",
    "print \"airlines\", set(data2014.UNIQUE_CARRIER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now focus on the main airports. We look for airports that have on average 50 domestic flight everyday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restrict_example(data):\n",
    "    ''' \n",
    "    Restrict dataset to airports for the example\n",
    "    '''  \n",
    "    \n",
    "    data.drop(data[(data.ORIGIN != 'JFK') & (data.ORIGIN != 'LGA') & (data.ORIGIN != 'EWR') & \\\n",
    "                  (data.DEST != 'ORD')].index, inplace=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points 205309\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "restrict_example(data2014)\n",
    "print \"number of points\", len(data2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove all airports that have an annual traffic under threshold\n",
    "\n",
    "def restrict_airport(data, threshold):\n",
    "    ''' \n",
    "    Drop carriers from the data set.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       dataframe  \n",
    "\n",
    "    droplist: <list 'string'>\n",
    "        List of carriers to be droppped\n",
    "    '''     \n",
    "    \n",
    "    dict_count = data.groupby(\"DEST\").agg(['count']).LAT.to_dict()['count']\n",
    "    \n",
    "    for key in dict_count:\n",
    "        if dict_count[key] < threshold:\n",
    "            data.drop(data[data.DEST == key].index, inplace=True)\n",
    "            data.drop(data[data.ORIGIN == key].index, inplace=True)\n",
    "    \n",
    "    print data.groupby(\"DEST\").agg(['count']).LAT.to_dict()['count']\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** WARNING ** \\\n",
    "RUN THIS CELL ONLY ONCE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of airports:  12\n",
      "dataset size:  205309\n",
      "Wall time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#restrict_airport(data2014, 60*365)\n",
    "data_example = data2014.copy()\n",
    "print \"number of airports: \", len(set(data2014))\n",
    "print \"dataset size: \", len(data2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save the restricted data to avoid computing them again\n",
    "file_path = \"cache/predictionData/data_example.csv\"\n",
    "data_example.to_csv(path_or_buf= file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>AIRCRAFT_YEAR</th>\n",
       "      <th>AIRCRAFT_MFR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>900</td>\n",
       "      <td>1225</td>\n",
       "      <td>13</td>\n",
       "      <td>2475</td>\n",
       "      <td>1987</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>40.633333</td>\n",
       "      <td>-73.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>900</td>\n",
       "      <td>1225</td>\n",
       "      <td>1</td>\n",
       "      <td>2475</td>\n",
       "      <td>1987</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>40.633333</td>\n",
       "      <td>-73.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>900</td>\n",
       "      <td>1225</td>\n",
       "      <td>59</td>\n",
       "      <td>2475</td>\n",
       "      <td>1986</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>40.633333</td>\n",
       "      <td>-73.783333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FL_DATE UNIQUE_CARRIER ORIGIN DEST  CRS_DEP_TIME  CRS_ARR_TIME  \\\n",
       "0  2014-01-01             AA    JFK  LAX           900          1225   \n",
       "1  2014-01-02             AA    JFK  LAX           900          1225   \n",
       "2  2014-01-04             AA    JFK  LAX           900          1225   \n",
       "\n",
       "   ARR_DELAY  DISTANCE AIRCRAFT_YEAR                    AIRCRAFT_MFR  \\\n",
       "0         13      2475          1987  BOEING                           \n",
       "1          1      2475          1987  BOEING                           \n",
       "2         59      2475          1986  BOEING                           \n",
       "\n",
       "         LAT       LONG  \n",
       "0  40.633333 -73.783333  \n",
       "1  40.633333 -73.783333  \n",
       "2  40.633333 -73.783333  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_example.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "# recover file\n",
    "#file_path = \"cache/predictionData/dataRes.csv\"\n",
    "#dataRes = pd.read_csv(file_path)\n",
    "#dataRes.drop('Unnamed: 0', axis= 1, inplace = True)\n",
    "#print dataRes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import strptime\n",
    "days = {0:\"Mon\", 1:\"Tues\", 2:\"Wed\", 3:\"Thurs\", 4:\"Fri\", 5:\"Sat\", 6:\"Sun\"}\n",
    "months = {1:\"Jan\", 2:\"Feb\", 3:\"Mar\", 4:\"Apr\", 5:\"May\", 6:\"June\", 7:\"July\", 8:\"Aug\", 9:\"Sep\", \\\n",
    "          10:\"Oct\", 11:\"Nov\", 12:\"Dec\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adjust_time(data):\n",
    "    monlist = np.empty(len(data), dtype = str)\n",
    "    daylist = np.empty(len(data), dtype = str)\n",
    "    \n",
    "    for i in xrange(len(data)):\n",
    "        date= strptime(data.FL_DATE.iloc[i], \"%Y-%M-%d\")\n",
    "        monlist[i] = months[date.tm_min]\n",
    "        daylist[i] = days[date.tm_wday]\n",
    "\n",
    "    return monlist, daylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'FL_DATE', u'UNIQUE_CARRIER', u'ORIGIN', u'DEST', u'CRS_DEP_TIME',\n",
       "       u'CRS_ARR_TIME', u'ARR_DELAY', u'DISTANCE', u'AIRCRAFT_YEAR',\n",
       "       u'AIRCRAFT_MFR', u'LAT', u'LONG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_example.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Index([u'UNIQUE_CARRIER', u'ORIGIN', u'DEST', u'CRS_DEP_TIME', u'CRS_ARR_TIME',\n",
      "       u'ARR_DELAY', u'DISTANCE', u'AIRCRAFT_YEAR', u'AIRCRAFT_MFR', u'LAT',\n",
      "       u'LONG', u'MONTH', u'DAY'],\n",
      "      dtype='object')\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "monlist, daylist = adjust_time(data_example)\n",
    "print \"OK\"\n",
    "data_example['MONTH'] = pd.Series(monlist, index=data_example.index)\n",
    "data_example['DAY'] = pd.Series(daylist, index=data_example.index)\n",
    "if 'FL_DATE' in data_example.columns:\n",
    "    data_example.drop('FL_DATE', axis = 1, inplace= True)\n",
    "print data_example.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Index([u'UNIQUE_CARRIER', u'ORIGIN', u'DEST', u'CRS_DEP_TIME', u'CRS_ARR_TIME',\n",
      "       u'ARR_DELAY', u'DISTANCE', u'AIRCRAFT_YEAR', u'AIRCRAFT_MFR', u'LAT',\n",
      "       u'LONG', u'MONTH', u'DAY'],\n",
      "      dtype='object')\n",
      "Wall time: 445 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "monlist, daylist = adjust_time(dexample)\n",
    "print \"OK\"\n",
    "dexample['MONTH'] = pd.Series(monlist, index=dexample.index)\n",
    "dexample['DAY'] = pd.Series(daylist, index=dexample.index)\n",
    "if 'FL_DATE' in dexample.columns:\n",
    "    dexample.drop('FL_DATE', axis = 1, inplace= True)\n",
    "print dexample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the script to put time in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before change:  0    1225\n",
      "1    1225\n",
      "Name: CRS_ARR_TIME, dtype: int64\n",
      "\n",
      "after change:  0    745\n",
      "1    745\n",
      "Name: CRS_ARR_TIME_COR, dtype: int64\n",
      "Wall time: 825 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ti = lambda x: x/100*60+x%100\n",
    "data_example['CRS_ARR_TIME_COR'] = data_example.CRS_ARR_TIME.map(ti)\n",
    "data_example['CRS_DEP_TIME_COR'] = data_example.CRS_DEP_TIME.map(ti)\n",
    "data_example.drop(['CRS_DEP_TIME', 'CRS_ARR_TIME'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 92 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dexample['CRS_ARR_TIME_COR'] = dexample.CRS_ARR_TIME.map(ti)\n",
    "dexample['CRS_DEP_TIME_COR'] = dexample.CRS_DEP_TIME.map(ti)\n",
    "dexample.drop(['CRS_DEP_TIME', 'CRS_ARR_TIME'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to center and normalize all continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # change the age of the aircraft from a string type to an integer type\n",
    "data_example.drop(data_example[data_example.AIRCRAFT_YEAR =='    '].index, inplace = True)\n",
    "data_example['AIRCRAFT_YEAR_COR'] = data_example.AIRCRAFT_YEAR.map(lambda x: int(x))\n",
    "data_example.drop('AIRCRAFT_YEAR', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dexample.drop(dexample[dexample.AIRCRAFT_YEAR =='    '].index, inplace = True)\n",
    "dexample['AIRCRAFT_YEAR_COR'] = dexample.AIRCRAFT_YEAR.map(lambda x: int(x))\n",
    "dexample.drop('AIRCRAFT_YEAR', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    mean = np.mean(array)\n",
    "    std = np.std(array)\n",
    "    return [(x - mean)/std for x in array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_data(data, feature_list):\n",
    "    ''' \n",
    "    Normalize data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       dataframe  \n",
    "\n",
    "    feature_list: <list 'string'>\n",
    "        List of features to be normalized\n",
    "    '''           \n",
    "\n",
    "    for feature in feature_list:\n",
    "        if feature in data.columns:\n",
    "            data[feature + '_NOR'] = normalize(data[feature].values)\n",
    "            data.drop(feature, axis =1, inplace=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "normalize_feature = ['CRS_DEP_TIME_COR', 'CRS_ARR_TIME_COR', 'DISTANCE', 'LONG', 'LAT', 'AIRCRAFT_YEAR_COR']\n",
    "normalize_data(data_example, normalize_feature)\n",
    "normalize_data(dexample, normalize_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in whetehr a flight will be more than 15 minutes late. So we adjust the ARR_DELAY colum to an indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_example['ARR_DELAY_COR'] = data_example.ARR_DELAY.map(lambda x: (x >= 15))\n",
    "#data_example.drop('ARR_DELAY', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_list = ['UNIQUE_CARRIER', 'ORIGIN', 'DEST', 'AIRCRAFT_MFR', 'MONTH','DAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "finalData_example = pd.get_dummies(data_example, columns=encoded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save the restricted data to avoid computing them again\n",
    "file_path = \"cache/predictionData/finalData_example.csv\"\n",
    "finalData_example.to_csv(path_or_buf= file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "# recover data2014 from cache/predictionData folder\n",
    "#file_path = \"cache/predictionData/finalData.csv\"\n",
    "#finalData = pd.read_csv(file_path)\n",
    "#finalData.drop('Unnamed: 0', axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make prediction on the variable 'ARR_DEL15'. This variable takes the value 1 is the plane is more than 15 minutes late and 0 if not. Let's look at the baseline classifier, that is the classifiers that assign repectively 1 or 0 to 'ARR_DEL15' for every flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "def baseline(data, target):\n",
    "    ''' \n",
    "    Compute the baseline classifiers along a target variable for a data set data\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       dataframe  \n",
    "\n",
    "    target: string\n",
    "        Column of data along wich we compute the baseline classifiers\n",
    "    '''    \n",
    "    \n",
    "    \n",
    "    score_baseline_1 = np.size(data[data[target] == 1][target].values) / np.size(data[target].values)\n",
    "    score_baseline_0 = np.size(data[data[target] == 0][target].values) / np.size(data[target].values)\n",
    "    \n",
    "    print \"baseline classifier everyone to 0: \", int(score_baseline_0*100) , \"%\"\n",
    "    print \"baseline classifier everyone to 1: \", int(score_baseline_1*100) , \"%\"\n",
    "   \n",
    "    return score_baseline_0, score_baseline_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#score_baseline_0, score_baseline_1 = baseline(finalData_example, 'ARR_DELAY_COR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's split the data set into a training set and a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(data, list_drop, target, test_size):\n",
    "    ''' \n",
    "    Splits the data into a training and a test set\n",
    "    Separates the training and test sets according to a feature set and a target set\n",
    "    Balance the features sets by retaining only fraction of its points\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       Flight dataframe  \n",
    "\n",
    "    list_drop: <list 'string'>\n",
    "        List of columns to exclude from the features set\n",
    "        \n",
    "    target: string\n",
    "        target column along whch we make the target set\n",
    "        \n",
    "    test_size: float\n",
    "        size of the test set\n",
    "    \n",
    "    '''    \n",
    "    \n",
    "    #split the dataset into a training set and a test set\n",
    "    dtrain, dtest = train_test_split(data, test_size = 0.3)\n",
    "    \n",
    "    Xtrain = dtrain.drop(list_drop, axis=1).values\n",
    "    ytrain = dtrain[target].values\n",
    "    Xtest = dtest.drop(list_drop, axis=1).values\n",
    "    ytest = dtest[target].values\n",
    "    \n",
    "    return Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ARR_DELAY', u'CRS_DEP_TIME_COR_NOR', u'CRS_ARR_TIME_COR_NOR',\n",
       "       u'DISTANCE_NOR', u'LONG_NOR', u'LAT_NOR', u'AIRCRAFT_YEAR_COR_NOR',\n",
       "       u'UNIQUE_CARRIER_AA', u'UNIQUE_CARRIER_B6', u'UNIQUE_CARRIER_OO', \n",
       "       ...\n",
       "       u'MONTH_J', u'MONTH_M', u'MONTH_N', u'MONTH_O', u'MONTH_S', u'DAY_F',\n",
       "       u'DAY_M', u'DAY_S', u'DAY_T', u'DAY_W'],\n",
       "      dtype='object', length=227)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalData_example.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xtest, ytest = split(finalData_example, ['ARR_DELAY'], 'ARR_DELAY', 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_random_forest(Xtrain, ytrain, Xtest, ytest, n_trees=10, max_features='auto'):\n",
    "    ''' \n",
    "    Fits a random forest with (Xtrain ,ytrain)\n",
    "    Computes the score on (Xtest, ytest)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    Xtrain: numpy 2D array\n",
    "       Feature training set\n",
    "\n",
    "    ytrain: numpy 1D array\n",
    "        Target training set\n",
    "    \n",
    "    Xtest: numpy 2D array\n",
    "       Feature test set\n",
    "\n",
    "    ytest: numpy 1D array\n",
    "        Target test set\n",
    "    \n",
    "    n_trees: int\n",
    "        number of trees in the forest\n",
    "    \n",
    "    max_features: string or int\n",
    "        number of features used for every tree\n",
    "        \n",
    "    Outputs:\n",
    "    --------\n",
    "    \n",
    "    score_train: float\n",
    "        score on the train set\n",
    "    \n",
    "    score_test: float\n",
    "        score on the test set\n",
    "    \n",
    "    clf.feature_importances_\n",
    "        weights of each feature as used by the classifier\n",
    "    \n",
    "    ''' \n",
    "\n",
    "    clf= RandomForestRegressor(n_estimators=n_trees, max_features= max_features)\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    \n",
    "    score_train = mean_squared_error(clf.predict(Xtrain), ytrain)\n",
    "    score_test = mean_squared_error(clf.predict(Xtest), ytest)\n",
    "    \n",
    "    return  score_train, score_test, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_parameters(Xtrain, ytrain, Xtest, ytest, nb_trees, nb_features):\n",
    "    ''' \n",
    "    Fits sequentially random forest classifiers\n",
    "    Adds each test score in a pandas.DataFrame with the number of trees, the loss function, the train score,\n",
    "    and the importance of each features\n",
    "    Returns a DataFrame with all scores\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    Xtrain: numpy 2D array\n",
    "       Feature training set\n",
    "\n",
    "    ytrain: numpy 1D array\n",
    "        Target training set\n",
    "    \n",
    "    Xtest: numpy 2D array\n",
    "       Feature test set\n",
    "\n",
    "    ytest: numpy 1D array\n",
    "        Target test set\n",
    "    \n",
    "    n_trees: <list int>\n",
    "        list of numbers of trees in the forest\n",
    "    \n",
    "    nb_features: <list int>\n",
    "        list of number of features in the forest\n",
    "        \n",
    "    Outputs:\n",
    "    --------\n",
    "    \n",
    "    score_tab: pandas.DataFrame\n",
    "        DataFrame of scores with associated parameters\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    score_tab = pd.DataFrame(columns=['nb_trees', 'nb_features', 'test_score', 'train_score', 'classifier'])\n",
    "    \n",
    "    # counter will increment the index in score_tab\n",
    "    counter = 0 \n",
    "\n",
    "    for n_estimators in nb_trees:\n",
    "        for max_features in nb_features:\n",
    "\n",
    "            score_train, score_test, classifier = \\\n",
    "            score_random_forest(Xtrain, ytrain, Xtest, ytest, n_trees=n_estimators, max_features=max_features) \n",
    "            score_tab.loc[counter] = [n_estimators, max_features, score_test, score_train, classifier]\n",
    "            counter += 1\n",
    "\n",
    "    return score_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_random_forest(data, list_drop, target, test_size=0.4, nb_trees=[10], nb_features = ['auto']):\n",
    "    Xtrain, ytrain, Xtest, ytest = split(data, list_drop, target, test_size)\n",
    "    scores =  best_parameters(Xtrain, ytrain, Xtest, ytest, nb_trees, nb_features)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_trees = [50]\n",
    "nb_features = ['log2']\n",
    "test_size = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nb_trees nb_features   test_score  train_score  \\\n",
      "0        50        log2  2344.664596   549.668531   \n",
      "\n",
      "                                          classifier  \n",
      "0  (DecisionTreeRegressor(criterion='mse', max_de...  \n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "randomForest2014 =  classify_random_forest(finalData_example, ['ARR_DELAY'], 'ARR_DELAY', test_size=test_size, nb_trees=nb_trees, nb_features=nb_features)\n",
    "print randomForest2014.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save file to /data/ folder\n",
    "file_path = \"cache/predictionData/randomForest2014.csv\"\n",
    "randomForest2014.to_csv(path_or_buf= file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the importance coefficients, that the average usage of each coefficients in the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_clf = randomForest2014[randomForest2014.test_score = np.max(randomForest2014.test_score.values)].classifier.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xexample = dexample.drop(list_drop, axis=1).values\n",
    "yexample = dexample[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Describe Process*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Predicting flight delay time with Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow users to enjoy more than a classfication experience we want to give them an expected delay time in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import required modules for prediction tasks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import zipfile\n",
    "import StringIO\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "# sklearn functions used for the linear regression model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us again establish a baseline which has to be beaten by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n"
     ]
    }
   ],
   "source": [
    "# first step is to load the actual data and exclude rows that are unnecessary\n",
    "# a script that produces the csv file can be found in the src folder\n",
    "# (it might take some while to run, on my macbook up to one hour)\n",
    "print('loading data...')\n",
    "df = pd.read_csv('cache/BigFlightTable.csv', nrows=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As flight delay changes over the time of day, we introduce a new feature which models in a categorical variable 10 Minute time windows. I.e. each window is fitted to have some effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
