{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Delay Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predicting whether a flight is late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Data acquisition and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import required modules for prediction tasks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reads all predefined months for a year and merge into one data frame\n",
    "rawData2014 = pd.DataFrame.from_csv('cache/predictionData/complete2014Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print rawData2014.columns\n",
    "rawData2014.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When cleaning the data set, we have to remove the following entries:\n",
    "\n",
    "- flights that have been cancelled or diverted. We focus on predicting the delay. As a result, we also remove the columns associated with diverted flights.\n",
    "- colmuns that give the answer. This is the case of many colmuns related to the arrival of the plane\n",
    "- rows where a value is missing\n",
    "\n",
    "Note that data points have to be cleaned in this order because most flights have empty entries for the 'diverted' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#entries to be dropped in the analysis\n",
    "columns_dropped = ['index', 'TAIL_NUM', 'FL_NUM', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF', \\\n",
    "                   'WHEELS_ON', 'TAXI_IN', 'ARR_TIME', 'CANCELLED', 'CANCELLATION_CODE', 'AIR_TIME', \\\n",
    "                   'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(data, list_col):\n",
    "    ''' \n",
    "    Creates a dataset by excluding undesirable columns\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       Flight dataframe  \n",
    "\n",
    "    list_col: <list 'string'>\n",
    "        Comumns to exclude from the data set\n",
    "    '''\n",
    "    \n",
    "    data.drop(data[data.CANCELLED == 0].index, inplace=True)\n",
    "    data.drop(list_col, axis=1, inplace=True)\n",
    "    data.dropna(axis = 0, inplace = True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data2014 = clean(rawData2014.copy(), columns_dropped)\n",
    "print data2014.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# save the data to avoid computing them again\n",
    "file_path = \"cache/predictionData/predictionData2014.csv\"\n",
    "data2014.to_csv(path_or_buf= file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# recover data2014 from cache/predictionData folder\n",
    "file_path = \"cache/predictionData/predictionData2014.csv\"\n",
    "data2014 = pd.read_csv(file_path)\n",
    "data2014.drop('Unnamed: 0', axis= 1, inplace = True)\n",
    "data2014.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test that clean did the job\n",
    "print \"size of raw data set: \", len(rawData2014)\n",
    "print \"number of cancelled: \", len(rawData2014[(rawData2014.CANCELLED == 1)])\n",
    "print \"size of data set: \", len(data2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add an example that we will follow all along. The example looks a ta flight from New York to Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>AIRCRAFT_YEAR</th>\n",
       "      <th>AIRCRAFT_MFR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>700</td>\n",
       "      <td>850</td>\n",
       "      <td>-17</td>\n",
       "      <td>733</td>\n",
       "      <td>1991</td>\n",
       "      <td>MCDONNELL DOUGLAS</td>\n",
       "      <td>40.766667</td>\n",
       "      <td>-73.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>700</td>\n",
       "      <td>850</td>\n",
       "      <td>32</td>\n",
       "      <td>733</td>\n",
       "      <td>2007</td>\n",
       "      <td>FRIEDEMANN JON</td>\n",
       "      <td>40.766667</td>\n",
       "      <td>-73.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>AA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>700</td>\n",
       "      <td>850</td>\n",
       "      <td>11</td>\n",
       "      <td>733</td>\n",
       "      <td>2007</td>\n",
       "      <td>FRIEDEMANN JON</td>\n",
       "      <td>40.766667</td>\n",
       "      <td>-73.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FL_DATE UNIQUE_CARRIER ORIGIN DEST  CRS_DEP_TIME  CRS_ARR_TIME  \\\n",
       "2033  2014-01-01             AA    LGA  ORD           700           850   \n",
       "2034  2014-01-04             AA    LGA  ORD           700           850   \n",
       "2035  2014-01-05             AA    LGA  ORD           700           850   \n",
       "\n",
       "      ARR_DELAY  DISTANCE AIRCRAFT_YEAR                    AIRCRAFT_MFR  \\\n",
       "2033        -17       733          1991  MCDONNELL DOUGLAS                \n",
       "2034         32       733          2007  FRIEDEMANN JON                   \n",
       "2035         11       733          2007  FRIEDEMANN JON                   \n",
       "\n",
       "            LAT       LONG  \n",
       "2033  40.766667 -73.866667  \n",
       "2034  40.766667 -73.866667  \n",
       "2035  40.766667 -73.866667  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dexample = data2014[data2014.DEST == 'ORD'][(data2014.ORIGIN == 'JFK')  | (data2014.ORIGIN == 'LGA') | \\\n",
    "                                              (data2014.ORIGIN == 'EWR')].copy()\n",
    "\n",
    "dexample.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restricting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has more than 4 millions entries, which makes any data manipulation extremely costly - let alone model fitting. We will therefore make some restrictions on the airports and the airlines considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNIQUE_CARRIER\n",
       "AA    137960\n",
       "AS    157312\n",
       "B6    225303\n",
       "DL    644768\n",
       "EV    616920\n",
       "F9     81758\n",
       "FL     69486\n",
       "HA     73370\n",
       "MQ      2995\n",
       "OO    586067\n",
       "UA    471093\n",
       "US    381688\n",
       "VX     57056\n",
       "WN    597821\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2014.groupby('UNIQUE_CARRIER').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in the carrier that operates from New York to Chicago. Looking at the table, we also notice that Atlantic Southeast Airlines (airline code EV) is only marginally present. So we drop it from the list of carriers we will study in addition to the other carriers that do not operate on the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNIQUE_CARRIER\n",
       "AA     126\n",
       "B6     955\n",
       "EV       2\n",
       "OO     191\n",
       "UA    6821\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dexample.groupby('UNIQUE_CARRIER').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def restrict_carrier(data, droplist):\n",
    "    ''' \n",
    "    Drop carriers from the data set.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       dataframe  \n",
    "\n",
    "    droplist: <list 'string'>\n",
    "        List of carriers to be droppped\n",
    "    '''        \n",
    "    \n",
    "    for item in droplist:\n",
    "        data.drop(data[data.UNIQUE_CARRIER == item].index, inplace= True)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points 1420423\n",
      "airlines set(['AA', 'OO', 'B6', 'UA'])\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "drop_airline = [ 'AS','DL', 'EV', 'F9', 'FL', 'HA', 'MQ', 'US', 'VX', 'WN']\n",
    "restrict_carrier(data2014, drop_airline)\n",
    "print \"number of points\", len(data2014)\n",
    "print \"airlines\", set(data2014.UNIQUE_CARRIER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now focus on the main airports. We look for airports that have on average 50 domestic flight everyday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restrict_example(data):\n",
    "    ''' \n",
    "    Restrict dataset to airports for the example\n",
    "    '''  \n",
    "    \n",
    "    data.drop(data[(data.ORIGIN != 'JFK') & (data.ORIGIN != 'LGA') & (data.ORIGIN != 'EWR') & \\\n",
    "                  (data.DEST != 'ORD')].index, inplace=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points 205309\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "restrict_example(data2014)\n",
    "print \"number of points\", len(data2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove all airports that have an annual traffic under threshold\n",
    "\n",
    "def restrict_airport(data, threshold):\n",
    "    ''' \n",
    "    Drop carriers from the data set.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       dataframe  \n",
    "\n",
    "    droplist: <list 'string'>\n",
    "        List of carriers to be droppped\n",
    "    '''     \n",
    "    \n",
    "    dict_count = data.groupby(\"DEST\").agg(['count']).LAT.to_dict()['count']\n",
    "    \n",
    "    for key in dict_count:\n",
    "        if dict_count[key] < threshold:\n",
    "            data.drop(data[data.DEST == key].index, inplace=True)\n",
    "            data.drop(data[data.ORIGIN == key].index, inplace=True)\n",
    "    \n",
    "    print data.groupby(\"DEST\").agg(['count']).LAT.to_dict()['count']\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** WARNING ** \\\n",
    "RUN THIS CELL ONLY ONCE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of airports:  12\n",
      "dataset size:  205309\n",
      "Wall time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#restrict_airport(data2014, 60*365)\n",
    "data_example = data2014.copy()\n",
    "print \"number of airports: \", len(set(data2014))\n",
    "print \"dataset size: \", len(data2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save the restricted data to avoid computing them again\n",
    "file_path = \"cache/predictionData/data_example.csv\"\n",
    "data_example.to_csv(path_or_buf= file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>AIRCRAFT_YEAR</th>\n",
       "      <th>AIRCRAFT_MFR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>900</td>\n",
       "      <td>1225</td>\n",
       "      <td>13</td>\n",
       "      <td>2475</td>\n",
       "      <td>1987</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>40.633333</td>\n",
       "      <td>-73.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>900</td>\n",
       "      <td>1225</td>\n",
       "      <td>1</td>\n",
       "      <td>2475</td>\n",
       "      <td>1987</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>40.633333</td>\n",
       "      <td>-73.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>900</td>\n",
       "      <td>1225</td>\n",
       "      <td>59</td>\n",
       "      <td>2475</td>\n",
       "      <td>1986</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>40.633333</td>\n",
       "      <td>-73.783333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FL_DATE UNIQUE_CARRIER ORIGIN DEST  CRS_DEP_TIME  CRS_ARR_TIME  \\\n",
       "0  2014-01-01             AA    JFK  LAX           900          1225   \n",
       "1  2014-01-02             AA    JFK  LAX           900          1225   \n",
       "2  2014-01-04             AA    JFK  LAX           900          1225   \n",
       "\n",
       "   ARR_DELAY  DISTANCE AIRCRAFT_YEAR                    AIRCRAFT_MFR  \\\n",
       "0         13      2475          1987  BOEING                           \n",
       "1          1      2475          1987  BOEING                           \n",
       "2         59      2475          1986  BOEING                           \n",
       "\n",
       "         LAT       LONG  \n",
       "0  40.633333 -73.783333  \n",
       "1  40.633333 -73.783333  \n",
       "2  40.633333 -73.783333  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_example.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "# recover file\n",
    "#file_path = \"cache/predictionData/dataRes.csv\"\n",
    "#dataRes = pd.read_csv(file_path)\n",
    "#dataRes.drop('Unnamed: 0', axis= 1, inplace = True)\n",
    "#print dataRes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import strptime\n",
    "days = {0:\"Mon\", 1:\"Tues\", 2:\"Wed\", 3:\"Thurs\", 4:\"Fri\", 5:\"Sat\", 6:\"Sun\"}\n",
    "months = {1:\"Jan\", 2:\"Feb\", 3:\"Mar\", 4:\"Apr\", 5:\"May\", 6:\"June\", 7:\"July\", 8:\"Aug\", 9:\"Sep\", \\\n",
    "          10:\"Oct\", 11:\"Nov\", 12:\"Dec\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adjust_time(data):\n",
    "    monlist = np.empty(len(data), dtype = str)\n",
    "    daylist = np.empty(len(data), dtype = str)\n",
    "    \n",
    "    for i in xrange(len(data)):\n",
    "        date= strptime(data.FL_DATE.iloc[i], \"%Y-%M-%d\")\n",
    "        monlist[i] = months[date.tm_min]\n",
    "        daylist[i] = days[date.tm_wday]\n",
    "\n",
    "    return monlist, daylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'FL_DATE', u'UNIQUE_CARRIER', u'ORIGIN', u'DEST', u'CRS_DEP_TIME',\n",
       "       u'CRS_ARR_TIME', u'ARR_DELAY', u'DISTANCE', u'AIRCRAFT_YEAR',\n",
       "       u'AIRCRAFT_MFR', u'LAT', u'LONG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_example.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Index([u'UNIQUE_CARRIER', u'ORIGIN', u'DEST', u'CRS_DEP_TIME', u'CRS_ARR_TIME',\n",
      "       u'ARR_DELAY', u'DISTANCE', u'AIRCRAFT_YEAR', u'AIRCRAFT_MFR', u'LAT',\n",
      "       u'LONG', u'MONTH', u'DAY'],\n",
      "      dtype='object')\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "monlist, daylist = adjust_time(data_example)\n",
    "print \"OK\"\n",
    "data_example['MONTH'] = pd.Series(monlist, index=data_example.index)\n",
    "data_example['DAY'] = pd.Series(daylist, index=data_example.index)\n",
    "if 'FL_DATE' in data_example.columns:\n",
    "    data_example.drop('FL_DATE', axis = 1, inplace= True)\n",
    "print data_example.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Index([u'UNIQUE_CARRIER', u'ORIGIN', u'DEST', u'CRS_DEP_TIME', u'CRS_ARR_TIME',\n",
      "       u'ARR_DELAY', u'DISTANCE', u'AIRCRAFT_YEAR', u'AIRCRAFT_MFR', u'LAT',\n",
      "       u'LONG', u'MONTH', u'DAY'],\n",
      "      dtype='object')\n",
      "Wall time: 445 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "monlist, daylist = adjust_time(dexample)\n",
    "print \"OK\"\n",
    "dexample['MONTH'] = pd.Series(monlist, index=dexample.index)\n",
    "dexample['DAY'] = pd.Series(daylist, index=dexample.index)\n",
    "if 'FL_DATE' in dexample.columns:\n",
    "    dexample.drop('FL_DATE', axis = 1, inplace= True)\n",
    "print dexample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the script to put time in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before change:  0    1225\n",
      "1    1225\n",
      "Name: CRS_ARR_TIME, dtype: int64\n",
      "\n",
      "after change:  0    745\n",
      "1    745\n",
      "Name: CRS_ARR_TIME_COR, dtype: int64\n",
      "Wall time: 825 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ti = lambda x: x/100*60+x%100\n",
    "data_example['CRS_ARR_TIME_COR'] = data_example.CRS_ARR_TIME.map(ti)\n",
    "data_example['CRS_DEP_TIME_COR'] = data_example.CRS_DEP_TIME.map(ti)\n",
    "data_example.drop(['CRS_DEP_TIME', 'CRS_ARR_TIME'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 92 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dexample['CRS_ARR_TIME_COR'] = dexample.CRS_ARR_TIME.map(ti)\n",
    "dexample['CRS_DEP_TIME_COR'] = dexample.CRS_DEP_TIME.map(ti)\n",
    "dexample.drop(['CRS_DEP_TIME', 'CRS_ARR_TIME'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to center and normalize all continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # change the age of the aircraft from a string type to an integer type\n",
    "data_example.drop(data_example[data_example.AIRCRAFT_YEAR =='    '].index, inplace = True)\n",
    "data_example['AIRCRAFT_YEAR_COR'] = data_example.AIRCRAFT_YEAR.map(lambda x: int(x))\n",
    "data_example.drop('AIRCRAFT_YEAR', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dexample.drop(dexample[dexample.AIRCRAFT_YEAR =='    '].index, inplace = True)\n",
    "dexample['AIRCRAFT_YEAR_COR'] = dexample.AIRCRAFT_YEAR.map(lambda x: int(x))\n",
    "dexample.drop('AIRCRAFT_YEAR', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    mean = np.mean(array)\n",
    "    std = np.std(array)\n",
    "    return [(x - mean)/std for x in array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_data(data, feature_list):\n",
    "    ''' \n",
    "    Normalize data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       dataframe  \n",
    "\n",
    "    feature_list: <list 'string'>\n",
    "        List of features to be normalized\n",
    "    '''           \n",
    "\n",
    "    for feature in feature_list:\n",
    "        if feature in data.columns:\n",
    "            data[feature + '_NOR'] = normalize(data[feature].values)\n",
    "            data.drop(feature, axis =1, inplace=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "normalize_feature = ['CRS_DEP_TIME_COR', 'CRS_ARR_TIME_COR', 'DISTANCE', 'LONG', 'LAT', 'AIRCRAFT_YEAR_COR']\n",
    "normalize_data(data_example, normalize_feature)\n",
    "normalize_data(dexample, normalize_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in whetehr a flight will be more than 15 minutes late. So we adjust the ARR_DELAY colum to an indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_example['ARR_DELAY_COR'] = data_example.ARR_DELAY.map(lambda x: (x >= 15))\n",
    "#data_example.drop('ARR_DELAY', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_list = ['UNIQUE_CARRIER', 'ORIGIN', 'DEST', 'AIRCRAFT_MFR', 'MONTH','DAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "finalData_example = pd.get_dummies(data_example, columns=encoded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save the restricted data to avoid computing them again\n",
    "file_path = \"cache/predictionData/finalData_example.csv\"\n",
    "finalData_example.to_csv(path_or_buf= file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "# recover data2014 from cache/predictionData folder\n",
    "#file_path = \"cache/predictionData/finalData.csv\"\n",
    "#finalData = pd.read_csv(file_path)\n",
    "#finalData.drop('Unnamed: 0', axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Baseline classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make prediction on the variable 'ARR_DEL15'. This variable takes the value 1 is the plane is more than 15 minutes late and 0 if not. Let's look at the baseline classifier, that is the classifiers that assign repectively 1 or 0 to 'ARR_DEL15' for every flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "def baseline(data, target):\n",
    "    ''' \n",
    "    Compute the baseline classifiers along a target variable for a data set data\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       dataframe  \n",
    "\n",
    "    target: string\n",
    "        Column of data along wich we compute the baseline classifiers\n",
    "    '''    \n",
    "    \n",
    "    \n",
    "    score_baseline_1 = np.size(data[data[target] == 1][target].values) / np.size(data[target].values)\n",
    "    score_baseline_0 = np.size(data[data[target] == 0][target].values) / np.size(data[target].values)\n",
    "    \n",
    "    print \"baseline classifier everyone to 0: \", int(score_baseline_0*100) , \"%\"\n",
    "    print \"baseline classifier everyone to 1: \", int(score_baseline_1*100) , \"%\"\n",
    "   \n",
    "    return score_baseline_0, score_baseline_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#score_baseline_0, score_baseline_1 = baseline(finalData_example, 'ARR_DELAY_COR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's split the data set into a training set and a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(data, list_drop, target, test_size):\n",
    "    ''' \n",
    "    Splits the data into a training and a test set\n",
    "    Separates the training and test sets according to a feature set and a target set\n",
    "    Balance the features sets by retaining only fraction of its points\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    data: pandas.DataFrame\n",
    "       Flight dataframe  \n",
    "\n",
    "    list_drop: <list 'string'>\n",
    "        List of columns to exclude from the features set\n",
    "        \n",
    "    target: string\n",
    "        target column along whch we make the target set\n",
    "        \n",
    "    test_size: float\n",
    "        size of the test set\n",
    "    \n",
    "    '''    \n",
    "    \n",
    "    #split the dataset into a training set and a test set\n",
    "    dtrain, dtest = train_test_split(data, test_size = 0.3)\n",
    "    \n",
    "    Xtrain = dtrain.drop(list_drop, axis=1).values\n",
    "    ytrain = dtrain[target].values\n",
    "    Xtest = dtest.drop(list_drop, axis=1).values\n",
    "    ytest = dtest[target].values\n",
    "    \n",
    "    return Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ARR_DELAY', u'CRS_DEP_TIME_COR_NOR', u'CRS_ARR_TIME_COR_NOR',\n",
       "       u'DISTANCE_NOR', u'LONG_NOR', u'LAT_NOR', u'AIRCRAFT_YEAR_COR_NOR',\n",
       "       u'UNIQUE_CARRIER_AA', u'UNIQUE_CARRIER_B6', u'UNIQUE_CARRIER_OO', \n",
       "       ...\n",
       "       u'MONTH_J', u'MONTH_M', u'MONTH_N', u'MONTH_O', u'MONTH_S', u'DAY_F',\n",
       "       u'DAY_M', u'DAY_S', u'DAY_T', u'DAY_W'],\n",
       "      dtype='object', length=227)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalData_example.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xtest, ytest = split(finalData_example, ['ARR_DELAY'], 'ARR_DELAY', 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_random_forest(Xtrain, ytrain, Xtest, ytest, n_trees=10, max_features='auto'):\n",
    "    ''' \n",
    "    Fits a random forest with (Xtrain ,ytrain)\n",
    "    Computes the score on (Xtest, ytest)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    Xtrain: numpy 2D array\n",
    "       Feature training set\n",
    "\n",
    "    ytrain: numpy 1D array\n",
    "        Target training set\n",
    "    \n",
    "    Xtest: numpy 2D array\n",
    "       Feature test set\n",
    "\n",
    "    ytest: numpy 1D array\n",
    "        Target test set\n",
    "    \n",
    "    n_trees: int\n",
    "        number of trees in the forest\n",
    "    \n",
    "    max_features: string or int\n",
    "        number of features used for every tree\n",
    "        \n",
    "    Outputs:\n",
    "    --------\n",
    "    \n",
    "    score_train: float\n",
    "        score on the train set\n",
    "    \n",
    "    score_test: float\n",
    "        score on the test set\n",
    "    \n",
    "    clf.feature_importances_\n",
    "        weights of each feature as used by the classifier\n",
    "    \n",
    "    ''' \n",
    "\n",
    "    clf= RandomForestRegressor(n_estimators=n_trees, max_features= max_features)\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    \n",
    "    score_train = mean_squared_error(clf.predict(Xtrain), ytrain)\n",
    "    score_test = mean_squared_error(clf.predict(Xtest), ytest)\n",
    "    \n",
    "    return  score_train, score_test, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_parameters(Xtrain, ytrain, Xtest, ytest, nb_trees, nb_features):\n",
    "    ''' \n",
    "    Fits sequentially random forest classifiers\n",
    "    Adds each test score in a pandas.DataFrame with the number of trees, the loss function, the train score,\n",
    "    and the importance of each features\n",
    "    Returns a DataFrame with all scores\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    Xtrain: numpy 2D array\n",
    "       Feature training set\n",
    "\n",
    "    ytrain: numpy 1D array\n",
    "        Target training set\n",
    "    \n",
    "    Xtest: numpy 2D array\n",
    "       Feature test set\n",
    "\n",
    "    ytest: numpy 1D array\n",
    "        Target test set\n",
    "    \n",
    "    n_trees: <list int>\n",
    "        list of numbers of trees in the forest\n",
    "    \n",
    "    nb_features: <list int>\n",
    "        list of number of features in the forest\n",
    "        \n",
    "    Outputs:\n",
    "    --------\n",
    "    \n",
    "    score_tab: pandas.DataFrame\n",
    "        DataFrame of scores with associated parameters\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    score_tab = pd.DataFrame(columns=['nb_trees', 'nb_features', 'test_score', 'train_score', 'classifier'])\n",
    "    \n",
    "    # counter will increment the index in score_tab\n",
    "    counter = 0 \n",
    "\n",
    "    for n_estimators in nb_trees:\n",
    "        for max_features in nb_features:\n",
    "\n",
    "            score_train, score_test, classifier = \\\n",
    "            score_random_forest(Xtrain, ytrain, Xtest, ytest, n_trees=n_estimators, max_features=max_features) \n",
    "            score_tab.loc[counter] = [n_estimators, max_features, score_test, score_train, classifier]\n",
    "            counter += 1\n",
    "\n",
    "    return score_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_random_forest(data, list_drop, target, test_size=0.4, nb_trees=[10], nb_features = ['auto']):\n",
    "    Xtrain, ytrain, Xtest, ytest = split(data, list_drop, target, test_size)\n",
    "    scores =  best_parameters(Xtrain, ytrain, Xtest, ytest, nb_trees, nb_features)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_trees = [50]\n",
    "nb_features = ['log2']\n",
    "test_size = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nb_trees nb_features   test_score  train_score  \\\n",
      "0        50        log2  2344.664596   549.668531   \n",
      "\n",
      "                                          classifier  \n",
      "0  (DecisionTreeRegressor(criterion='mse', max_de...  \n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "randomForest2014 =  classify_random_forest(finalData_example, ['ARR_DELAY'], 'ARR_DELAY', test_size=test_size, nb_trees=nb_trees, nb_features=nb_features)\n",
    "print randomForest2014.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save file to /data/ folder\n",
    "file_path = \"cache/predictionData/randomForest2014.csv\"\n",
    "randomForest2014.to_csv(path_or_buf= file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the importance coefficients, that the average usage of each coefficients in the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_clf = randomForest2014[randomForest2014.test_score = np.max(randomForest2014.test_score.values)].classifier.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xexample = dexample.drop(list_drop, axis=1).values\n",
    "yexample = dexample[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Describe Process*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Predicting flight delay time with Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow users to enjoy more than a classfication experience we want to give them an expected delay time in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import required modules for prediction tasks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import zipfile\n",
    "import StringIO\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn functions used for the linear regression model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us again establish a baseline which has to be beaten by our model. To get a feeling for a good baseline we pick flights from from New York(all airports) to Chicago(all airports)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n"
     ]
    }
   ],
   "source": [
    "# first step is to load the actual data and exclude rows that are unnecessary\n",
    "# a script that produces the csv file can be found in the src folder\n",
    "# (it might take some while to run, on my macbook up to one hour)\n",
    "print('loading data...')\n",
    "bigdf = pd.read_csv('cache/Big5FlightTable.csv')\n",
    "\n",
    "years = ['2010', '2011', '2012', '2013', '2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify here which cities should be investigated\n",
    "city_from = 'New York, NY'\n",
    "city_to = 'Chicago, IL'\n",
    "\n",
    "# filter for cities\n",
    "bigdf = bigdf[(bigdf.ORIGIN_CITY_NAME == city_from) & (bigdf.DEST_CITY_NAME == city_to)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. A first predictor\n",
    "For a span of days we are interested in knoweledge, which flight we should take. Therefore let's choose the popular date for Christmas returning flights 21.12.2015 as example. As we want to use historical data, let's get first clear what data we have. Is it possible to compare flights over the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x234cb07d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAC5CAYAAAA4eHs5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMAAYQkAYICwBAAwQFgCABjwfytdxrsp1CfUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1123a82d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_day = 21\n",
    "query_month = 12\n",
    "\n",
    "# how many flights do exist in all years?\n",
    "flights = []\n",
    "flightvalues = []\n",
    "for y in years:\n",
    "    query = list(bigdf[(bigdf.YEAR == int(y)) & (bigdf.MONTH == query_month) & (bigdf.DAY_OF_MONTH == query_day)].FL_NUM.astype(int).unique())\n",
    "    flights.append(query)\n",
    "    flightvalues += query\n",
    "    \n",
    "# build a matrix\n",
    "data_matrix = np.zeros((len(flightvalues), len(years)))\n",
    "# build dict\n",
    "flightdict = dict(zip(flightvalues, np.arange(0, len(flightvalues))))\n",
    "\n",
    "# fill datamatrix\n",
    "for i in xrange(len(years)):\n",
    "    for j in flights[i]:\n",
    "        data_matrix[flightdict[j], i] = 1.\n",
    "        \n",
    "# plot matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(data_matrix, extent=[0,data_matrix.shape[0],0,data_matrix.shape[1] * 5], \\\n",
    "           interpolation='none', cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plot shows, flight numbers are not stable over the years and it is not trivial to find a matching.\n",
    "Thus comparison by features for individual flights is not really possible. \n",
    "It seems as if airlines change their flight numbers on a yearly basis. \n",
    "Thus we need to come up with another idea and use a latent variable based approach instead.\n",
    "One of the easiest ideas is to average the delay time over each day as a base classifier and refine then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffordate = bigdf[bigdf.MONTH == query_month]\n",
    "dffordate = dffordate[dffordate.DAY_OF_MONTH == query_day]\n",
    "dffordate.head()\n",
    "\n",
    "def predict_base_model(X):\n",
    "    return np.array([dffordate.ARR_DELAY.mean()]*X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the quality of this model, we use the last year as test set and the previous as train data. The idea is, that we are always interested in predicting the next year somehow. Thus, if the match for 2014 is good, we expect it to be the same for 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build test/train set\n",
    "df_train = dffordate[dffordate.YEAR != int(years[-1])]\n",
    "df_test = dffordate[dffordate.YEAR == int(years[-1])]\n",
    "\n",
    "y_train = df_train.ARR_DELAY\n",
    "X_train = y_train # here dummy\n",
    "y_test = df_test.ARR_DELAY\n",
    "X_test = y_test # here dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the base model, the prediction for 2014 is that we are going to be 27.72 minutes late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.728260869565219"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_base_model(X_test)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good did it perform comparing the actual arrival delay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.10756003440288"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(((y - y_pred)**2).mean())\n",
    "\n",
    "def mas(y, y_pred):\n",
    "    return (np.abs(y - y_pred)).mean()\n",
    "\n",
    "MAS_base = mas(y_test, y_pred)\n",
    "RMSE_base = rmse(y_test, y_pred)\n",
    "RMSE_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the root mean squared error as one (of many possible) measures, any model that we develop should beat the benchmark of 44."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Building a linear regression model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As flight delay changes over the time of day like explored in the data exploration part, we introduce a new feature which models in a categorical variable 10 minute time windows. I.e. for each window we introduce a latent variable that captures some sort of delay influence of this frame. This is done for both the departure and the arrival time. The model here is first developed for the reduced dataset containing the flights between New York / Chicago only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.05 s, sys: 212 ms, total: 3.27 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigdf['HOUR_OF_ARR'] = 0\n",
    "bigdf['HOUR_OF_DEP'] = 0\n",
    "\n",
    "for index, row in bigdf.iterrows():\n",
    "    bigdf.set_value(index, 'HOUR_OF_ARR', int(row['ARR_TIME']) / 10)\n",
    "    bigdf.set_value(index, 'HOUR_OF_DEP', int(row['DEP_TIME']) / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, before fitting the actual model categorical variables need to be encoded as binary features (they have no order!) and numerical features shall be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into numerical and categorical features\n",
    "numericalFeat = bigdf[['DISTANCE', 'AIRCRAFT_AGE']].astype('float') \n",
    "categoricalFeat = bigdf[['MONTH', 'DAY_OF_MONTH', 'ORIGIN', 'DEST', \\\n",
    "                         'HOUR_OF_ARR', 'HOUR_OF_DEP', 'UNIQUE_CARRIER', \\\n",
    "                         'DAY_OF_WEEK', 'AIRCRAFT_MFR']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with categorical variables\n",
    "Luckily, sklearn has a routine to do this for us. Yet, as it is only able to handle integers we first reindex all categorical features we create lookup tables for the values. This turned out to be one of the slowest step in processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/pandas/core/indexing.py:415: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 s, sys: 104 ms, total: 13 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for the next step, all features need to be encoded as integers --> create lookup Tables!\n",
    "def transformToID(df, col):\n",
    "    vals = df[col].unique()\n",
    "    LookupTable = dict(zip(vals, np.arange(len(vals))))\n",
    "    for key in LookupTable.keys():\n",
    "        df[df[col] == key] = LookupTable[key]\n",
    "    return (LookupTable, df)\n",
    "\n",
    "mfrDict, categoricalFeat = transformToID(categoricalFeat, 'AIRCRAFT_MFR')\n",
    "originDict, categoricalFeat = transformToID(categoricalFeat, 'ORIGIN')\n",
    "destDict, categoricalFeat = transformToID(categoricalFeat, 'DEST')\n",
    "carrierDict, categoricalFeat = transformToID(categoricalFeat, 'UNIQUE_CARRIER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>HOUR_OF_ARR</th>\n",
       "      <th>HOUR_OF_DEP</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRCRAFT_MFR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MONTH  DAY_OF_MONTH ORIGIN DEST  HOUR_OF_ARR  HOUR_OF_DEP UNIQUE_CARRIER  \\\n",
       "921      0             0      0    0            0            0              0   \n",
       "922      1             1      1    1            1            1              1   \n",
       "923      0             0      0    0            0            0              0   \n",
       "924      0             0      0    0            0            0              0   \n",
       "925      2             2      2    2            2            2              2   \n",
       "\n",
       "     DAY_OF_WEEK AIRCRAFT_MFR  \n",
       "921            0            0  \n",
       "922            1            1  \n",
       "923            0            0  \n",
       "924            0            0  \n",
       "925            2            2  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricalFeat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn the variables are now encoded. As we have many variables (around 1200 in the final model for the whole year) using sparse matrices was critical for us to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.2 ms, sys: 10 ms, total: 58.3 ms\n",
      "Wall time: 59.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "encoder = OneHotEncoder() \n",
    "categoricals_encoded = encoder.fit_transform(categoricalFeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recombining categorical and numerical features allows to start the usual Machine Learning routine (split into test/train, normalize, train/cross-validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/scipy/sparse/compressed.py:739: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "numericals_sparse = sparse.csr_matrix(numericalFeat)\n",
    "# get data matrix & response variable\n",
    "X_all = sparse.hstack((numericals_sparse, categoricals_encoded))\n",
    "y_all = bigdf['ARR_DELAY'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# we have 2 numerical features\n",
    "X_train_numericals = X_train[:, 0:3].toarray()\n",
    "X_test_numericals = X_test[:, 0:3].toarray()\n",
    "\n",
    "# use sklearn tools to standardize numerical features...\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train_numericals) # get std/mean from train set\n",
    "X_train_numericals = sparse.csr_matrix(scaler.transform(X_train_numericals)) \n",
    "X_test_numericals = sparse.csr_matrix(scaler.transform(X_test_numericals))\n",
    "\n",
    "# update sets\n",
    "X_train[:, 0:3] = X_train_numericals\n",
    "X_test[:, 0:3] = X_test_numericals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal least squares regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.323925698812779"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# fit the model!\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "rmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first model, we use OLS to get a feeling of what is achievable using a reduced dataset. The motivation for this is mainly to see whether this might be used to speedup the whole process. As the RMSE reveals, we did not do better than the base classifier. What happened? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31881, 74), (74,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, clf.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the number of variables (74 here), it might be that either the fit is not good enough or we are ignoring the dependency of flight delays within different routes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.01 s, sys: 52 ms, total: 2.06 s\n",
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use ridge regression (i.e. Gaussian prior) and vary the lambda parameter using Grid search\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "SGD_params = {'alpha': 10.0 ** -np.arange(-2,8)}\n",
    "SGD_model = GridSearchCV(SGDRegressor(random_state = 42), \\\n",
    "                         SGD_params, scoring = 'mean_absolute_error', cv = 6) # cross validate 6 times\n",
    "\n",
    "\n",
    "# train the model, this might take some time...\n",
    "SGD_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.389335267933092"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = SGD_model.predict(X_test)\n",
    "rmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the RMSE again is a bit disappointing. We did worse than OLS and the base classifier! This means, it is now time to tackle the unavoidable: Regressing the whole dataset!\n",
    "\n",
    "As the data becomes rapidly huge (for 1 year ~ 700MB uncompressed CSV, 5 years ~ 3.5GB, 10 years ~ 7.2GB) the code to perform the actual regression has been developed first in an IPython notebook and then run separately. It can be found in the `src` folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression over the whole data\n",
    "In the following `2` models based on `1, 5` years of data are used (saved in `BigFlightTable.csv, Big5FlightTable.csv`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFUCAYAAABldzZDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvgAAGEb4AgBg2P8DThQ24zaYlgYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a59f050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def load_model(filename):\n",
    "    mdl = None\n",
    "    with open(filename, 'r') as f:\n",
    "        mdl = json.load(f)\n",
    "    return mdl\n",
    "\n",
    "# load model results\n",
    "mdl1 = load_model('results/models/2014model.json') # model with 2014 data (1 year)\n",
    "mdl5 = load_model('results/models/2010_2014model.json') # model with 2010-2014 data ( 5 years)\n",
    "\n",
    "\n",
    "labels = np.array(['base predictor', '1 year LM', '5 year LM'])\n",
    "RMSEs = np.array([RMSE_base, mdl1['RMSE'], mdl5['RMSE']])\n",
    "MASs = np.array([MAS_base, mdl1['MAS'], mdl5['MAS']])\n",
    "\n",
    "width = .35\n",
    "xx = np.arange(len(RMSEs))\n",
    "plt.bar(xx-width, RMSEs, width, label='RMSE', color=sns.color_palette()[0])\n",
    "plt.bar(xx , MASs, width, label='MAE', color=sns.color_palette()[2])\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Hide major tick labels\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "\n",
    "# Customize minor tick labels\n",
    "ax.xaxis.set_minor_locator(ticker.FixedLocator([i for i in xx]))\n",
    "ax.xaxis.set_minor_formatter(ticker.FixedFormatter([labels[i] for i in xx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the RMSEs and Mean absolute error we see that the linear regression model over the whole data clearly outperformed the baseline predictor. Also, more data did not really tremendously improve the mean absolute error but we can see a clear variance reduction in the RMSE. To further improve the model, additional variables should be included. One of the next ideas is weather data. As formatted historic weather data is unfortunately not for free available and scraping it for 100Ks entries per year is not feasible, the variables could not be added to the model. Another interesting idea might be to include some more meta data. I.e. an variable measuring the effect of holidays and variables accounting for winds which could be based by geographic location (i.e. a flight in western direction is longer than one in eastern direction b/c of the passat wind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Application: Predicting the best flight for a given date and route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime, tzinfo\n",
    "from pytz import timezone\n",
    "import pytz\n",
    "\n",
    "def convertToUTC(naive, zonestring=\"America/New_York\"):\n",
    "    local = pytz.timezone (zonestring)\n",
    "    local_dt = local.localize(naive, is_dst=None)\n",
    "    return local_dt.astimezone (pytz.utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we want to give an example on how to perform a prediction using the model from 2010-2014. We choose the route Chicago / New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are only interested in flights NY to Chicago!\n",
    "city_to = 'Chicago, IL'\n",
    "city_from = 'New York, NY'\n",
    "zone_to = 'America/Chicago'\n",
    "zone_from = 'America/New_York'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially before Christmas, it is a good question to ask on which day you should fly and which flight to take. Therefore, we consider only flights between 20.12-24.12. Our assumption is that many values we feed in our predictor do not change, i.e. we can use the data from 2014 (stored in BigFlightTable.csv). For a productive system, these queries should be performed using a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4376277 entries\n",
      "5 days have 58334 flights\n",
      "Found 87 flights from New York, NY to Chicago, IL for 20.12 - 24.12\n"
     ]
    }
   ],
   "source": [
    "# need to create a lookup table for the values (i.e. flight numbers, city and so on and then drop all duplicates!)\n",
    "db = pd.read_csv('cache/BigFlightTable.csv')\n",
    "# remove all unnecessary columns\n",
    "db = db[['ORIGIN_CITY_NAME', 'DEST_CITY_NAME', 'AIRCRAFT_AGE', 'DEST', 'ARR_TIME', \\\n",
    "         'DEP_TIME', 'UNIQUE_CARRIER', 'DAY_OF_WEEK', 'AIRCRAFT_MFR', 'FL_NUM', 'MONTH', \\\n",
    "         'DAY_OF_MONTH', 'DISTANCE', 'ORIGIN']]\n",
    "print str(db.count()[0]) + ' entries'\n",
    "db.head()\n",
    "\n",
    "# drop everything except for the 5 days before christmas! i.e. 20.12, 21.12, 22.12, 23.12, 24.12.\n",
    "db = db[db.MONTH == 12]\n",
    "db = db[db.DAY_OF_MONTH <= 24]\n",
    "db = db[db.DAY_OF_MONTH >= 20]\n",
    "\n",
    "print '5 days have ' + str(db.count()[0]) + ' flights'\n",
    "\n",
    "db = db[db.ORIGIN_CITY_NAME == city_from]\n",
    "db = db[db.DEST_CITY_NAME == city_to]\n",
    "db.reset_index(inplace=True)\n",
    "\n",
    "print 'Found ' + str(db.count()[0]) + ' flights from ' + city_from + ' to ' + city_to + ' for 20.12 - 24.12'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know load our favourite model and setup the categorical variable encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = load_model('results/models/2014model.json')\n",
    "\n",
    "# categorical feature encoder, fitted on the keys\n",
    "encoder = OneHotEncoder(sparse=True, n_values=mdl['encoder']['values']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the lookuptables, it is straight-forward to write the prediction function. Note that variabales need to be normalized according to the training data used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input is a datarow\n",
    "# prediction of day in the next year!\n",
    "def predictDelayTime(row, mdl):\n",
    "    \n",
    "    s_mean, s_std, coeff, intercept = mdl['scaler_mean'], mdl['scaler_std'], mdl['coeff'], mdl['intercept']\n",
    "    \n",
    "    # read out tables\n",
    "    carrierTable = mdl['CARRIER']\n",
    "    mfrTable = mdl['MANUFACTURER']\n",
    "    destTable = mdl['DEST']\n",
    "    originTable = mdl['ORIGIN']\n",
    "    \n",
    "    distance = row['DISTANCE'] # <-- look this up!\n",
    "    aircraft_age = row['AIRCRAFT_AGE'] # <-- look this up!\n",
    "    \n",
    "    # normalize numerical features according to scaler\n",
    "    distance = (distance - s_mean[0]) / s_std[0]\n",
    "    aircraft_age = (aircraft_age + 1 - s_mean[1]) / s_std[1]\n",
    "    \n",
    "    month = row['MONTH']\n",
    "    day_of_month = row['DAY_OF_MONTH'] \n",
    "    origin = row['ORIGIN']\n",
    "    dest = row['DEST']\n",
    "    \n",
    "    hour_of_arr = int(row['ARR_TIME']) / 10\n",
    "    hour_of_dep = int(row['DEP_TIME']) / 10\n",
    "    carrier = row['UNIQUE_CARRIER']\n",
    "    day_of_week = datetime(year=2015, month=row.MONTH, day=row.DAY_OF_MONTH).weekday() # <-- get via datetimeobject\n",
    "    mfr = row['AIRCRAFT_MFR']\n",
    "    \n",
    "    # for nonindexed categorical features, do lookup!\n",
    "    origin = originTable[origin]\n",
    "    dest = destTable[dest]\n",
    "    mfr = mfrTable[mfr]\n",
    "    carrier = carrierTable[carrier]\n",
    "\n",
    "    # write into df\n",
    "    df = {}\n",
    "    df['MONTH'] = month\n",
    "    df['DAY_OF_MONTH'] = day_of_month\n",
    "    df['ORIGIN'] = origin\n",
    "    df['DEST'] = dest\n",
    "    df['HOUR_OF_ARR'] = hour_of_arr\n",
    "    df['HOUR_OF_DEP'] = hour_of_dep\n",
    "    df['UNIQUE_CARRIER'] = carrier\n",
    "    df['DAY_OF_WEEK'] = day_of_week\n",
    "    df['AIRCRAFT_MFR'] = mfr\n",
    "    df = pd.DataFrame([df])\n",
    "\n",
    "    # order here is important! make sure it is the same as in the model!\n",
    "    categoricalFeat = df[['MONTH', 'DAY_OF_MONTH', 'ORIGIN', \n",
    "                    'DEST', 'HOUR_OF_ARR', 'HOUR_OF_DEP', \n",
    "                    'UNIQUE_CARRIER', 'DAY_OF_WEEK', 'AIRCRAFT_MFR']].copy() # Categorical features\n",
    "    \n",
    "    # construct the data vector for the linear model\n",
    "    categoricals_encoded = encoder.fit_transform(categoricalFeat)\n",
    "    num_features = np.array([distance, aircraft_age])\n",
    "    cat_features = categoricals_encoded.toarray().T.ravel()\n",
    "    w = np.hstack([num_features, cat_features])\n",
    "\n",
    "    y_pred = np.dot(w, coeff) + intercept\n",
    "    \n",
    "    return y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to predict the delay time on our flights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0\n",
      "processing 1\n",
      "processing 2\n",
      "processing 3\n",
      "processing 4\n",
      "processing 5\n",
      "processing 6\n",
      "processing 7\n",
      "processing 8\n",
      "processing 9\n",
      "processing 10\n",
      "processing 11\n",
      "processing 12\n",
      "processing 13\n",
      "processing 14\n",
      "processing 15\n",
      "processing 16\n",
      "processing 17\n",
      "processing 18\n",
      "processing 19\n",
      "processing 20\n",
      "processing 21\n",
      "processing 22\n",
      "processing 23\n",
      "processing 24\n",
      "processing 25\n",
      "processing 26\n",
      "processing 27\n",
      "processing 28\n",
      "processing 29\n",
      "processing 30\n",
      "processing 31\n",
      "processing 32\n",
      "processing 33\n",
      "processing 34\n",
      "processing 35\n",
      "processing 36\n",
      "processing 37\n",
      "processing 38\n",
      "processing 39\n",
      "processing 40\n",
      "processing 41\n",
      "processing 42\n",
      "processing 43\n",
      "processing 44\n",
      "processing 45\n",
      "processing 46\n",
      "processing 47\n",
      "processing 48\n",
      "processing 49\n",
      "processing 50\n",
      "processing 51\n",
      "processing 52\n",
      "processing 53\n",
      "processing 54\n",
      "processing 55\n",
      "processing 56\n",
      "processing 57\n",
      "processing 58\n",
      "processing 59\n",
      "processing 60\n",
      "processing 61\n",
      "processing 62\n",
      "processing 63\n",
      "processing 64\n",
      "processing 65\n",
      "processing 66\n",
      "processing 67\n",
      "processing 68\n",
      "processing 69\n",
      "processing 70\n",
      "processing 71\n",
      "processing 72\n",
      "processing 73\n",
      "processing 74\n",
      "processing 75\n",
      "processing 76\n",
      "processing 77\n",
      "processing 78\n",
      "processing 79\n",
      "processing 80\n",
      "processing 81\n",
      "processing 82\n",
      "processing 83\n",
      "processing 84\n",
      "processing 85\n",
      "processing 86\n"
     ]
    }
   ],
   "source": [
    "# create for each day info\n",
    "db['PREDICTED_DELAY'] = 0.\n",
    "db['FLIGHT_TIME'] = 0\n",
    "db['PREDICTED_FLIGHT_TIME'] = 0\n",
    "for index, row in db.iterrows():\n",
    "    print 'processing {idx}'.format(idx=index)\n",
    "    y_pred = predictDelayTime(row, mdl)\n",
    "    db.set_value(index, 'PREDICTED_DELAY', y_pred)\n",
    "\n",
    "    arr_time = datetime(year=2015, month=row['MONTH'], day=row['DAY_OF_MONTH'], \\\n",
    "                        hour= int(row['ARR_TIME'] / 100), minute=int(row['ARR_TIME'] % 100))\n",
    "    dep_time = datetime(year=2015, month=row['MONTH'], day=row['DAY_OF_MONTH'], \\\n",
    "                        hour= int(row['DEP_TIME'] / 100), minute=int(row['DEP_TIME'] % 100))\n",
    "    \n",
    "    flight_time_in_min =  (convertToUTC(arr_time) - convertToUTC(dep_time))\n",
    "    flight_time_in_min = int(flight_time_in_min.total_seconds() / 60)\n",
    "    \n",
    "    db.set_value(index, 'FLIGHT_TIME', flight_time_in_min)\n",
    "    db.set_value(index, 'PREDICTED_FLIGHT_TIME', y_pred + flight_time_in_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the best flight on 22nd December?\n",
    "Using this info, we can get the best flights for the 22nd of December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db2 = db[db.DAY_OF_MONTH == 22]\n",
    "dbres2 = db2.sort('PREDICTED_FLIGHT_TIME')\n",
    "dbres2.to_csv('data/best_flights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On what day is it best to fly in the evening?\n",
    "Analogously, we now want our model to give us the answer which is the best flight during the busy evening hours (17:00-20:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>AIRCRAFT_AGE</th>\n",
       "      <th>DEST</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRCRAFT_MFR</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>PREDICTED_DELAY</th>\n",
       "      <th>FLIGHT_TIME</th>\n",
       "      <th>PREDICTED_FLIGHT_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4156108</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2</td>\n",
       "      <td>MDW</td>\n",
       "      <td>738</td>\n",
       "      <td>627</td>\n",
       "      <td>WN</td>\n",
       "      <td>1</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>490</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>725</td>\n",
       "      <td>LGA</td>\n",
       "      <td>-5.391739</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4235745</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>16</td>\n",
       "      <td>ORD</td>\n",
       "      <td>916</td>\n",
       "      <td>757</td>\n",
       "      <td>UA</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRBUS</td>\n",
       "      <td>463</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>733</td>\n",
       "      <td>LGA</td>\n",
       "      <td>0.540536</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4156107</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>14</td>\n",
       "      <td>MDW</td>\n",
       "      <td>1423</td>\n",
       "      <td>1304</td>\n",
       "      <td>WN</td>\n",
       "      <td>1</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>333</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>725</td>\n",
       "      <td>LGA</td>\n",
       "      <td>7.796969</td>\n",
       "      <td>79</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4237736</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>16</td>\n",
       "      <td>ORD</td>\n",
       "      <td>845</td>\n",
       "      <td>714</td>\n",
       "      <td>UA</td>\n",
       "      <td>1</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>1094</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>733</td>\n",
       "      <td>LGA</td>\n",
       "      <td>0.609249</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4237531</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>16</td>\n",
       "      <td>ORD</td>\n",
       "      <td>746</td>\n",
       "      <td>610</td>\n",
       "      <td>UA</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRBUS</td>\n",
       "      <td>683</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>733</td>\n",
       "      <td>LGA</td>\n",
       "      <td>-2.842361</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index ORIGIN_CITY_NAME DEST_CITY_NAME  AIRCRAFT_AGE DEST  ARR_TIME  \\\n",
       "19  4156108     New York, NY    Chicago, IL             2  MDW       738   \n",
       "59  4235745     New York, NY    Chicago, IL            16  ORD       916   \n",
       "18  4156107     New York, NY    Chicago, IL            14  MDW      1423   \n",
       "74  4237736     New York, NY    Chicago, IL            16  ORD       845   \n",
       "66  4237531     New York, NY    Chicago, IL            16  ORD       746   \n",
       "\n",
       "    DEP_TIME UNIQUE_CARRIER  DAY_OF_WEEK AIRCRAFT_MFR  FL_NUM  MONTH  \\\n",
       "19       627             WN            1       BOEING     490     12   \n",
       "59       757             UA            1       AIRBUS     463     12   \n",
       "18      1304             WN            1       BOEING     333     12   \n",
       "74       714             UA            1       BOEING    1094     12   \n",
       "66       610             UA            1       AIRBUS     683     12   \n",
       "\n",
       "    DAY_OF_MONTH  DISTANCE ORIGIN  PREDICTED_DELAY  FLIGHT_TIME  \\\n",
       "19            22       725    LGA        -5.391739           71   \n",
       "59            22       733    LGA         0.540536           79   \n",
       "18            22       725    LGA         7.796969           79   \n",
       "74            22       733    LGA         0.609249           91   \n",
       "66            22       733    LGA        -2.842361           96   \n",
       "\n",
       "    PREDICTED_FLIGHT_TIME  \n",
       "19                     65  \n",
       "59                     79  \n",
       "18                     86  \n",
       "74                     91  \n",
       "66                     93  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db3 = db[(db.DEP_TIME > 1700) & (db.DEP_TIME < 2000)]\n",
    "dbres3 = db2.sort('PREDICTED_FLIGHT_TIME')\n",
    "dbres3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the best day to fly for in the evening is the 22nd!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
